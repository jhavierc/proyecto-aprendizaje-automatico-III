{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed653bf4",
   "metadata": {},
   "source": [
    "# Modelo VAR (Vector Autoregression)\n",
    "\n",
    "Este notebook implementa modelos VAR multivariados para predecir las ventas de dos productos simultáneamente, utilizando tres tipos de validación temporal:\n",
    "- Walk-Forward Validation\n",
    "- Rolling Window\n",
    "- Expanding Window\n",
    "\n",
    "**Características del modelo:**\n",
    "- VAR es un modelo multivariado que predice múltiples series de tiempo simultáneamente\n",
    "- Considera las relaciones entre las series (producto1 y producto2)\n",
    "- Cada serie se modela como función de sus propios valores pasados y los valores pasados de las otras series\n",
    "- Utiliza Optimización Bayesiana para encontrar el mejor orden del modelo\n",
    "- Entrena el modelo final para producción con el mejor método de validación\n",
    "\n",
    "**Análisis Multivariado:**\n",
    "- Se incluyen análisis de correlación entre series\n",
    "- Verificación de estacionariedad\n",
    "- Análisis de interdependencias entre productos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf3d034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import warnings\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bf20a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado:\n",
      "Forma del dataset: (127, 2)\n",
      "\n",
      "Primeras filas:\n",
      "    producto1   producto2\n",
      "1  500.000000  200.000000\n",
      "2  497.400893  210.686220\n",
      "3  478.605317  222.018584\n",
      "4  486.454125  233.920990\n",
      "5  479.695678  238.402098\n",
      "\n",
      "Últimas filas:\n",
      "      producto1   producto2\n",
      "123  164.610771  629.293034\n",
      "124  150.881839  637.099467\n",
      "125  151.788470  653.155282\n",
      "126  137.047639  672.528345\n",
      "127  141.990873  676.058092\n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 127 entries, 1 to 127\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   producto1  127 non-null    float64\n",
      " 1   producto2  127 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 3.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('data-set.csv', index_col=0)\n",
    "print(\"Dataset cargado:\")\n",
    "print(f\"Forma del dataset: {df.shape}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "print(df.head())\n",
    "print(f\"\\nÚltimas filas:\")\n",
    "print(df.tail())\n",
    "print(f\"\\nInformación del dataset:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7cf677",
   "metadata": {},
   "source": [
    "## Análisis Multivariado: Exploración de las Series\n",
    "\n",
    "Antes de implementar el modelo VAR, realizamos análisis exploratorios para entender las relaciones entre las series.\n",
    "\n",
    "## Verificación de Estacionariedad\n",
    "\n",
    "El modelo VAR requiere que las series sean estacionarias. Verificamos la estacionariedad de las series originales antes de aplicar diferenciación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "624ea525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANÁLISIS DE CORRELACIÓN ENTRE SERIES\n",
      "============================================================\n",
      "\n",
      "Matriz de correlación:\n",
      "           producto1  producto2\n",
      "producto1   1.000000  -0.730748\n",
      "producto2  -0.730748   1.000000\n",
      "\n",
      "Correlación entre producto1 y producto2: -0.7307\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp4AAAJOCAYAAAAeSAe8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVQFJREFUeJzt3X98z/X+//H7+z3bezO2kdkQRmnIr5owv2X5GUdHR36cRFp1OiirzkH5WZnOKZRElH5Sis/pdCKOEJGDhqSQpJRsw5qxsV/v5/cPX++8beO99/u99364XS+X18Xez9evx/u1mYfH88fbYowxAgAAAEqYtbQDAAAAwNWBxBMAAAA+QeIJAAAAnyDxBAAAgE+QeAIAAMAnSDwBAADgEySeAAAA8AkSTwAAAPgEiSeAciM7O1szZszQmjVrSjsUAIAbSDxRIUydOlUWi6VE72GxWDR16tQSvUdZFxUVpREjRpTY9a/0jBMSErRkyRK1bdu2xGKA+0r65wNA+UfiiWJ54403ZLFYZLFYtHnz5gL7jTGqW7euLBaLbr/9drfuMWPGDH344YceRlo+5Ofn6/XXX1fXrl1VvXp12Ww2RUVFaeTIkfryyy9LO7wy5f3339eHH36oTz75RGFhYaUdzhW9/PLLeuONN3x2v88++8zxd9Niscjf318NGzbU8OHD9cMPP/gsjpK0dOlSzZkzp7TDAOABEk+4JTAwUEuXLi3QvnHjRv3yyy+y2WxuX9udxPPJJ5/U2bNn3b5naTh79qxuv/123XvvvTLGaOLEiZo/f76GDx+urVu3qk2bNvrll19KO0yfOnv2rJ588skC7cYY/fLLL/rkk09Ur169Uois+HydeF4wduxYvf3221q4cKH69u2rZcuW6ZZbbtGvv/7q81i8jcQTKP8qlXYAKJ/69OmjDz74QC+++KIqVfr9x2jp0qWKiYnRiRMnfBJHZmamgoODValSJac4yoPHH39cq1ev1uzZs/XII4847ZsyZYpmz57tlftceEaFycrKUuXKlb1yH28IDAwstN1isSghIcHH0fjO5b5HxdWpUyfdeeedkqSRI0fqhhtu0NixY/Xmm29qwoQJJX5/ALgcKp5wy5AhQ3Ty5EmtXbvW0ZaTk6Ply5dr6NChhZ7z3HPPqX379rrmmmsUFBSkmJgYLV++3OkYi8WizMxMvfnmm44uwwtjxi6M4/z22281dOhQVatWTR07dnTad8GIESOcuh0v3q40TjM7O1vjxo1TeHi4qlatqv79+xdZeTx69KjuvfdeRUREyGaz6cYbb9TixYuv9Pj0yy+/6JVXXtFtt91WIOmUJD8/Pz322GO69tprHW27du1S7969FRISoipVqqh79+763//+53TehaEQGzdu1EMPPaSaNWs6rtG1a1c1a9ZMSUlJ6ty5sypXrqyJEyc63vOUKVN0/fXXy2azqW7duvrb3/6m7Ozsy76PtLQ0PfbYY2revLmqVKmikJAQ9e7dW1999VWBY8+dO6epU6fqhhtuUGBgoGrVqqU//vGPOnTokOOYwr4/xXnfW7ZsUUJCgsLDwxUcHKw77rhDx48fv+x7uGD//v268847Vb16dQUGBqp169b66KOP3LpPVFSUvvnmG23cuNHxc9e1a1enaxT2PZKkTz75RJ06dVJwcLCqVq2qvn376ptvvnHpPRTm1ltvlSQdPnxY0uX/HuXl5empp57Sdddd5xj2MXHixAI/B8YYPf3007r22mtVuXJldevWrdAYixp7feEZ/Pjjj07tn3zyibp06aKqVasqJCREt9xyi6NnpWvXrlq5cqV++uknxzONiopynJuamqpRo0YpIiJCgYGBatmypd58880C937vvfcUExPjuEfz5s31wgsvuP5AAXikfJWIUGZERUUpNjZW7777rnr37i3p/D8ap06d0uDBg/Xiiy8WOOeFF15Q//79NWzYMOXk5Oi9997Tn/70J3388cfq27evJOntt9/WfffdpzZt2uj++++XJF133XVO1/nTn/6kRo0aacaMGTLGFBrfAw88oLi4OKe21atXa8mSJapZs+Zl39t9992nd955R0OHDlX79u21fv16R3wXS0lJUbt27WSxWDR69GiFh4frk08+0ahRo5SRkVFoQnnBJ598ory8PN19992XjeWCb775Rp06dVJISIj+9re/yd/fX6+88oq6du2qjRs3Fphs89BDDyk8PFyTJ09WZmamo/3kyZPq3bu3Bg8erD//+c+KiIiQ3W5X//79tXnzZt1///1q0qSJvv76a82ePVvffffdZYc9/PDDD/rwww/1pz/9SQ0aNFBKSopeeeUVdenSRd9++61q164t6fxY1ttvv13r1q3T4MGD9fDDD+v06dNau3at9u7dW+B77O77HjNmjKpVq6YpU6boxx9/1Jw5czR69GgtW7bsis+3Q4cOqlOnjsaPH6/g4GC9//77GjBggFasWKE77rijWPeZM2eOxowZoypVquiJJ56QJEVERFzxe/T222/rnnvuUc+ePfXss88qKytL8+fPV8eOHbVr1y6nRMtVFxL7a665xqm9sL9H9913n958803deeedevTRR7Vt2zYlJiZq3759+te//uU4d/LkyXr66afVp08f9enTRzt37lSPHj2Uk5NT7PgueOONN3Tvvffqxhtv1IQJExQWFqZdu3Zp9erVGjp0qJ544gmdOnVKv/zyi6M3oEqVKpLOD9Ho2rWrvv/+e40ePVoNGjTQBx98oBEjRig9PV0PP/ywJGnt2rUaMmSIunfvrmeffVaStG/fPm3ZssVxDIASZoBieP31140ks2PHDvPSSy+ZqlWrmqysLGOMMX/6059Mt27djDHG1K9f3/Tt29fp3AvHXZCTk2OaNWtmbr31Vqf24OBgc8899xS495QpU4wkM2TIkCL3FeXgwYMmNDTU3HbbbSYvL6/I43bv3m0kmYceesipfejQoUaSmTJliqNt1KhRplatWubEiRNOxw4ePNiEhoYWeL8XGzdunJFkdu3aVeQxFxswYIAJCAgwhw4dcrT9+uuvpmrVqqZz586Otgvfn44dOxZ4n126dDGSzIIFC5za3377bWO1Ws3nn3/u1L5gwQIjyWzZssXRVr9+fafvzblz50x+fr7TeYcPHzY2m81Mnz7d0bZ48WIjycyaNavAe7Pb7Y6vL33GxX3fcXFxTtcbN26c8fPzM+np6QXue7Hu3bub5s2bm3PnzjnF1b59e9OoUSO37nPjjTeaLl26FLhXUd+j06dPm7CwMBMfH+90fHJysgkNDS3QfqkNGzYYSWbx4sXm+PHj5tdffzUrV640UVFRxmKxmB07dhhjiv57dOFn/7777nNqf+yxx4wks379emOMMampqSYgIMD07dvX6RlMnDjRSHL6+Sjq7+WFZ3D48GFjjDHp6emmatWqpm3btubs2bNOx158j759+5r69esXuN6cOXOMJPPOO+842nJyckxsbKypUqWKycjIMMYY8/DDD5uQkJDL/g4AULLoaofbBg0apLNnz+rjjz/W6dOn9fHHHxfZzS5JQUFBjq9/++03nTp1Sp06ddLOnTuLdd8HH3ywWMdnZmbqjjvuULVq1fTuu+/Kz8+vyGNXrVol6fwEjYtdWr00xmjFihXq16+fjDE6ceKEY+vZs6dOnTp12feVkZEhSapateoV48/Pz9d///tfDRgwQA0bNnS016pVS0OHDtXmzZsd17sgPj6+0Pdps9k0cuRIp7YPPvhATZo0UePGjZ3ex4Uu2g0bNhQZm81mk9VqdcR58uRJValSRdHR0U7vf8WKFapRo4bGjBlT4BpFLYPlzvu+//77na7XqVMn5efn66effiryPaSlpWn9+vUaNGiQTp8+7Xj/J0+eVM+ePXXw4EEdPXrU4/tc6tLv0dq1a5Wenq4hQ4Y4fR/8/PzUtm3by34fLnbvvfcqPDxctWvXVt++fR1DV1q3bu103KV/jy787F86lvbRRx+VJK1cuVKS9OmnnyonJ0djxoxxegaXq/Bfydq1a3X69GmNHz++wDhfV5ZJW7VqlSIjIzVkyBBHm7+/v8aOHaszZ85o48aNkqSwsDBlZmY6DREC4Ft0tcNt4eHhiouL09KlS5WVlaX8/HzHpIbCfPzxx3r66ae1e/dupzFjxV1/s0GDBsU6Pj4+XocOHdIXX3xRoLvxUj/99JOsVmuBrt/o6Gin18ePH1d6eroWLlyohQsXFnqt1NTUIu8TEhIiSTp9+vQV4z9+/LiysrIKxCBJTZo0kd1u188//6wbb7zR0V7UM6pTp44CAgKc2g4ePKh9+/YpPDy82O/DbrfrhRde0Msvv6zDhw8rPz/fse/iZ33o0CFFR0cXawKYO+/70hnv1apVk3T+PzpF+f7772WM0aRJkzRp0qRCj0lNTVWdOnU8us+lLv0eHTx4UNLvYzIvdeFn5komT56sTp06yc/PTzVq1FCTJk0Kfe6X3v/Cz/7111/v1B4ZGamwsDBHUn3hz0aNGjkdFx4e7ngOxXVhOECzZs3cOv+nn35So0aNHP8JuqBJkyaO/dL54Q3vv/++evfurTp16qhHjx4aNGiQevXq5dZ9ARQfiSc8MnToUMXHxys5OVm9e/cucn3Fzz//XP3791fnzp318ssvq1atWvL399frr79e6LJMl3Nx5fRKXnjhBb377rt655131KpVq2Ld53Lsdrsk6c9//rPuueeeQo9p0aJFkec3btxYkvT11197Na4LinpGhbXb7XY1b95cs2bNKvScunXrFnmfGTNmaNKkSbr33nv11FNPqXr16rJarXrkkUccz8iXiqpmmyLGAku/fy8fe+wx9ezZs9BjLk3G3LnPpS79XlyI4+2331ZkZGSB411N2ps3b15gfLMr97/Amx/EcLlqdmmoWbOmdu/erTVr1uiTTz7RJ598otdff13Dhw8vdCISAO8j8YRH7rjjDj3wwAP63//+d9kJHCtWrFBgYKDWrFnjtMbn66+/XuBYb/3D9/nnn+uxxx7TI488omHDhrl0Tv369WW32x0VugsOHDjgdNyFGe/5+fku/SN/qd69e8vPz0/vvPPOFScYhYeHq3LlygVikM7PxLZarZdNDq/kuuuu01dffaXu3bsX+9kvX75c3bp102uvvebUnp6erho1ajjdY9u2bcrNzZW/v79L1y7p933BhW58f39/t76XRSnus7xQZa9Zs6ZX43DVhZ/9gwcPOiqF0vlJdOnp6apfv77jOOl8hfbiIRDHjx8vUPG9UAFNT093+k/ppUMSLrz3vXv3FkjyL1bUM61fv7727Nkju93uVPXcv3+/U8ySFBAQoH79+qlfv36y2+166KGH9Morr2jSpEmXvTcA72CMJzxSpUoVzZ8/X1OnTlW/fv2KPM7Pz08Wi8Wp0vHjjz8WOmM6ODhY6enpHsV17NgxDRo0SB07dtQ///lPl8+7MEP/0ln5ly5a7efnp4EDB2rFihXau3dvgetcaQmfunXrKj4+Xv/97381d+7cAvvtdruef/55/fLLL/Lz81OPHj3073//22n5mZSUFC1dulQdO3Z0uRu2MIMGDdLRo0e1aNGiAvvOnj3rNCv+Un5+fgWqfB988EGBMZEDBw7UiRMn9NJLLxW4RlFVwpJ+3xfUrFlTXbt21SuvvKJjx44V2O/qckyXKu7Pcc+ePRUSEqIZM2YoNzfXa3G4qk+fPpIK/qxfqIRfWNkhLi5O/v7+mjt3rtP3rrCF3S8klJs2bXK0XRhzerEePXqoatWqSkxM1Llz55z2XXyP4OBgnTp1qtDYk5OTnf7zm5eXp7lz56pKlSrq0qWLpPOrOlzMarU6eiautHQYAO+g4gmPFdXVfLG+fftq1qxZ6tWrl4YOHarU1FTNmzdP119/vfbs2eN0bExMjD799FPNmjVLtWvXVoMGDYr92dxjx47V8ePH9be//U3vvfee074WLVoU2Q3eqlUrDRkyRC+//LJOnTql9u3ba926dfr+++8LHDtz5kxt2LBBbdu2VXx8vJo2baq0tDTt3LlTn376qdLS0i4b4/PPP69Dhw5p7Nix+r//+z/dfvvtqlatmo4cOaIPPvhA+/fv1+DBgyVJTz/9tNauXauOHTvqoYceUqVKlfTKK68oOztb//jHP4r1bC5199136/3339eDDz6oDRs2qEOHDsrPz9f+/fv1/vvva82aNQUmplxw++23a/r06Ro5cqTat2+vr7/+WkuWLHGqhEnS8OHD9dZbbykhIUHbt29Xp06dlJmZqU8//VQPPfSQ/vCHPxR6/ZJ83xebN2+eOnbsqObNmys+Pl4NGzZUSkqKtm7dql9++aXQdUmvJCYmRvPnz9fTTz+t66+/XjVr1ixy/KZ0fgzn/Pnzdffdd+vmm2/W4MGDFR4eriNHjmjlypXq0KFDoYm7t7Rs2VL33HOPFi5cqPT0dHXp0kXbt2/Xm2++qQEDBqhbt26SzleiH3vsMSUmJur2229Xnz59tGvXLn3yySdOVW7pfEJZr149jRo1So8//rj8/Py0ePFix/u6+L3Pnj1b9913n2655RbH+qJfffWVsrKyHIlqTEyMli1bpoSEBN1yyy2qUqWK+vXrp/vvv1+vvPKKRowYoaSkJEVFRWn58uXasmWL5syZ45jEd9999yktLU233nqrrr32Wv3000+aO3euWrVq5VTlBVCCSm0+Pcqli5dTupzCllN67bXXTKNGjYzNZjONGzc2r7/+eqHLrezfv9907tzZBAUFOS3PcuHY48ePF7jfpde5sHRQYdvFy/UU5uzZs2bs2LHmmmuuMcHBwaZfv37m559/LvTclJQU89e//tXUrVvX+Pv7m8jISNO9e3ezcOHCy97jgry8PPPqq6+aTp06mdDQUOPv72/q169vRo4cWWCppZ07d5qePXuaKlWqmMqVK5tu3bqZL774wumYy31/unTpYm688cZC48jJyTHPPvusufHGG43NZjPVqlUzMTExZtq0aebUqVOO4wpbTunRRx81tWrVMkFBQaZDhw5m69atpkuXLgWWEsrKyjJPPPGEadCggeNZ3XnnnU5LJRX2jD153xeWGNqwYUOh7/tihw4dMsOHDzeRkZHG39/f1KlTx9x+++1m+fLlbt0nOTnZ9O3b11StWtVIcjyPK/0d2rBhg+nZs6cJDQ01gYGB5rrrrjMjRowwX3755WXjvxDDBx98cNnjLvf3KDc310ybNs3xPapbt66ZMGGC0zJTxhiTn59vpk2b5vi+d+3a1ezdu7fAz4cxxiQlJZm2bduagIAAU69ePTNr1qwCyyld8NFHH5n27duboKAgExISYtq0aWPeffddx/4zZ86YoUOHmrCwMCPJaWmllJQUM3LkSFOjRg0TEBBgmjdvbl5//XWn6y9fvtz06NHD1KxZ0xHPAw88YI4dO3bZZwbAeyzGFGM0PAAAAOAmxngCAADAJ0g8AQAA4BMkngAAAPAJEk8AAAD4BIknAAAAfILEEwAAAD5B4gkAAACfIPEEAACAT5B4AgAAwCfK3Ge1r/SPLu0QAJQBfXMPOL6On3GyFCMBUFYsmnhNaYcAD1HxBAAAgE+QeAIAAMAnSDwBAADgEySeAAAA8AkSTwAAAPgEiScAAAB8gsQTAAAAPkHiCQAAAJ8g8QQAAIBPkHgCAADAJ0g8AQAA4BMkngAAAPAJEk8AAAD4BIknAAAAfILEEwAAAD5B4gkAAACfIPEEAACAT5B4AgAAwCdIPAEAAOATJJ4AAADwCRJPAAAA+ASJJwAAAHyCxBMAAAA+QeIJAAAAnyDxBAAAgE+QeAIAAMAnSDwBAADgEySeAAAA8AkSTwAAAPgEiScAAAB8gsQTAAAAPkHiCQAAAJ8g8QQAAIBPkHgCAADAJ0g8AQAA4BMkngAAAPAJEk8AAAD4BIknAAAAfILEEwAAAD5B4gkAAACfIPEEAACAT5B4AgAAwCdIPAEAAOATJJ4AAADwCRJPAAAA+ASJJwAAQDm3adMm9evXT7Vr15bFYtGHH354xXM+++wz3XzzzbLZbLr++uv1xhtvlHicJJ4AAADlXGZmplq2bKl58+a5dPzhw4fVt29fdevWTbt379Yjjzyi++67T2vWrCnROCuV6NUBAABQ4nr37q3evXu7fPyCBQvUoEEDPf/885KkJk2aaPPmzZo9e7Z69uxZUmFS8QQAALjabN26VXFxcU5tPXv21NatW0v0vlQ8AQAAyqDs7GxlZ2c7tdlsNtlsNo+vnZycrIiICKe2iIgIZWRk6OzZswoKCvL4HoUh8QQAAPDQSv9or19zxxNDNG3aNKe2KVOmaOrUqV6/l6+QeAIAAJRBEyZMUEJCglObN6qdkhQZGamUlBSntpSUFIWEhJRYtVMi8QQAACiTvNWtXpjY2FitWrXKqW3t2rWKjY0tkftdQOIJAADgIYu/pVTvf+bMGX3//feO14cPH9bu3btVvXp11atXTxMmTNDRo0f11ltvSZIefPBBvfTSS/rb3/6me++9V+vXr9f777+vlStXlmiczGoHAAAo57788kvddNNNuummmyRJCQkJuummmzR58mRJ0rFjx3TkyBHH8Q0aNNDKlSu1du1atWzZUs8//7xeffXVEl1KSaLiCQAA4DFrpdKteHbt2lXGmCL3F/apRF27dtWuXbtKMKqCSDwBAAA8ZPGnE9kVPCUAAAD4BBVPAAAAD5V2V3t5QcUTAAAAPkHFEwAAwEOlvZxSeUHiCQAA4CG62l1DVzsAAAB8gsQTAAAAPkFXOwAAgIcY4+kaKp4AAADwCSqeAAAAHmJykWuoeAIAAMAnqHgCAAB4yOJHxdMVJJ4AAAAespJ4uoSudgAAAPgEFU8AAAAPWaxUPF1BxRMAAAA+QcUTAADAQxY/anmuIPEEAADwEJOLXEN6DgAAAJ8g8QQAAIBPkHgCAADAJxjjCQAA4CGWU3INiScAAICHmFzkGrraAQAA4BNUPAEAADxkoeLpEhJPAAAAD1msdCK7gqcEAAAAn6DiCQAA4CFmtbuGiicAAAB8goonAACAh1hOyTVUPAEAAOATJJ4AAADwCbraAQAAPMTkItdQ8QQAAIBPUPEEAADwEAvIu4bEEwAAwEN0tbuG9BwAAAA+QeIJAADgIaufxeubO+bNm6eoqCgFBgaqbdu22r59+2WPnzNnjqKjoxUUFKS6detq3LhxOnfunFv3dgWJJwAAQAWwbNkyJSQkaMqUKdq5c6datmypnj17KjU1tdDjly5dqvHjx2vKlCnat2+fXnvtNS1btkwTJ04ssRhJPAEAADxksVq8vhXXrFmzFB8fr5EjR6pp06ZasGCBKleurMWLFxd6/BdffKEOHTpo6NChioqKUo8ePTRkyJArVkk94dXE89ChQ7r11lu9eUkAAIAyz2K1en3Lzs5WRkaG05adnV3o/XNycpSUlKS4uDhHm9VqVVxcnLZu3VroOe3bt1dSUpIj0fzhhx+0atUq9enTx/sP6EJM3rzYmTNntHHjRm9eEgAA4KqUmJio0NBQpy0xMbHQY0+cOKH8/HxFREQ4tUdERCg5ObnQc4YOHarp06erY8eO8vf313XXXaeuXbuWaFd7sZZTevHFFy+7/+jRox4FAwAAUB6VxHJKEyZMUEJCglObzWbz2vU/++wzzZgxQy+//LLatm2r77//Xg8//LCeeuopTZo0yWv3uVixEs9HHnlEtWrVUkBAQKH7c3JyvBIUAADA1c5ms7mcaNaoUUN+fn5KSUlxak9JSVFkZGSh50yaNEl333237rvvPklS8+bNlZmZqfvvv19PPPGErCWwKH6xrli/fn3Nnj1bhw8fLnRbuXKl1wMEAADA5QUEBCgmJkbr1q1ztNntdq1bt06xsbGFnpOVlVUgufTz85MkGWNKJM5iJZ4xMTFKSkoqcr/FYimxQAEAAMqqsjCrPSEhQYsWLdKbb76pffv26S9/+YsyMzM1cuRISdLw4cM1YcIEx/H9+vXT/Pnz9d577+nw4cNau3atJk2apH79+jkSUG8rVlf79OnTlZWVVeT+pk2b6vDhwx4HBQAAgOK56667dPz4cU2ePFnJyclq1aqVVq9e7ZhwdOTIEacK55NPPimLxaInn3xSR48eVXh4uPr166dnnnmmxGK0mDJWolzpH13aIQAoA/rmHnB8HT/jZClGAqCsWDTxmtIOoUjfDenl9Wve8O5qr1+ztBWr4nmp48eP68CB8/84REdHKzw83CtBAQAAlCeWEpiIUxG59ZQyMzN17733qnbt2urcubM6d+6s2rVra9SoUZftigcAAMDVy63EMyEhQRs3btRHH32k9PR0paen69///rc2btyoRx991NsxAgAAlGlWP4vXt4rIra72FStWaPny5erataujrU+fPgoKCtKgQYM0f/58b8UHAACACsKtxDMrK6vARzJJUs2aNelqBwAAV52S+OSiisitrvbY2FhNmTJF586dc7SdPXtW06ZNK3KRUgAAgIrKYrV6fauI3Kp4zpkzR7169dK1116rli1bSpK++uorBQYGas2aNV4NEAAAABWDW4ln8+bNdfDgQS1ZskT79++XJA0ZMkTDhg1TUFCQVwMEAAAo6+hqd41bieemTZvUvn17xcfHO7Xn5eVp06ZN6ty5s1eCAwAAQMXh1gCCbt26KS0trUD7qVOn1K1bN4+DAgAAQMXjVsXTGCOLpWBJ+eTJkwoODvY4KAAAgPKErnbXFCvx/OMf/yhJslgsGjFihGw2m2Nffn6+9uzZo/bt23s3QgAAAFQIxUo8Q0NDJZ2veFatWtVpIlFAQIDatWtXYNwnAABARVdRlz/ytmIlnq+//rokKSoqSo8//rgqV65cIkEBAACUJ3S1u8at9Hz48OE6evRogfaDBw/qxx9/9DQmAAAAVEBuJZ4jRozQF198UaB927ZtGjFihKcxAQAAlCt8cpFr3HpXu3btUocOHQq0t2vXTrt37/Y0JgAAAFRAbi2nZLFYdPr06QLtp06dUn5+vsdB4epTvWNrNXx0lEJvbqbA2jX15cCHlPLRutIOC0AJ6t85SJ1aBaqyzaLvf8nVktWZSv3NXuTxiQ+FqUaYX4H2DUnntHRNpiTpz72D1STKX2FVrMrONTr0S55WbMhU8smirwt4RSHLTKIgtxLPzp07KzExUe+++678/M7/EsjPz1diYqI6duzo1QBxdfALrqyMPQf08xsr1Hr5vNIOB0AJ69UuUN1bB2rxf87oRLpdA7pU1iODQzR5YbryiqhfPPPGKV08f6NOeCUlDA3Rl/uyHW0/HcvTtr3ZSsuwKzjQon6dzl93wsvpMqaE3xSuakwuco1bieezzz6rzp07Kzo6Wp06dZIkff7558rIyND69eu9GiCuDsfXbNLxNZtKOwwAPtK9TZBWbjmrrw7mSpIW/+eMnn+4mm6KDtCOb3MKPedMlnPm2DvWX6lp+fruSJ6j7fPdvyehJ09JH27M0tT4MNUItep4OlVPoLS5NcazadOm2rNnjwYNGqTU1FSdPn1aw4cP1/79+9WsWTNvxwgAqEBqhFkVVsWqfYdzHW1ns41++DVPDeu4Vg/xs0ptm9m0ZU92kccE+EsdWtp0/Ld8pWWQdAJlgVsVT0mqXbu2ZsyY4c1YAABXgdDg8zWPjEznZPB0pt2x70puig5Q5UCLtuw5V2Bf15ttGnhrsAIDLDp2Ml+z381QPnknUCa4lXhu2nT5LtHOnTtfdn92drays53/l2qz2Zw+ghMAUDG0vTFAf+5dxfF67vsZHl+zY0ub9h7K1akzBQdubvsmR98ezlVoFat6tA3SA3dU1cy3ThU5dhTwhoq6/JG3uZV4du3atUCb5aLZXFea2Z6YmKhp06Y5tU2ZMkVTp051JxwAQBm2+2COfvg13fHa3+/8vxchwVadyvz934uqwVb9nJJ36ekFVA+xqkmUv15eUXB1Fel8t/3ZbKPU3+z64ehpvZBQXTdHB2h7EWNHAW9gcpFr3Eo8f/vtN6fXubm52rVrlyZNmqRnnnnmiudPmDBBCQkJTm1UOwGgYsrOkY7nOPd1p5+xq3GUv35OPZ94BgZY1LB2JW3cWbDr/FIdWtqUkWX09fe5VzzWYpFkkSr5kRQAZYFbiWdoaGiBtttuu00BAQFKSEhQUlLSZc+nWx2X8guurODr6zleV25wrUJaNlZO2imd+/lYKUYGoCSs235WfTsEKfW3fJ1It+sPnSsr/bRduw78XpVMGBqiXQdytCHp92TUIqlDC5u27smW/ZJe9hphVt3SJEDfHM7VmSyjalWt6hUbpNxco68PUe1EyaKr3TVuTy4qTEREhA4cOODNS+IqERrTTLHr3na8bvrcREnSz2/9n/aMmlBaYQEoIav/d04BARbd3buKKgdadPDnXL2wLMNpHGZ4mFVVKjtXKps08Nc1oX6FTirKzTNqVNdfcW2CVDnQooxMuw4eydPMt07pdBaLeAJlgcWY4i+pu2fPHqfXxhgdO3ZMM2fOVF5enjZv3ux2QCv9o90+F0DF0Tf39//Exs84WYqRACgrFk28prRDKFLK3+/2+jUjnn37ygeVM25VPFu1aiWLxaJLc9Z27dpp8eLFXgkMAACgvGBykWvcSjwPHz7s9NpqtSo8PFyBgYFeCQoAAAAVj1uJZ/369b0dBwAAQPnF5CKXuJx4vvjiiy5fdOzYsW4FAwAAgIrL5cRz9uzZTq+PHz+urKwshYWFSZLS09NVuXJl1axZk8QTAABcVS7+IB0UzeW68OHDhx3bM888o1atWmnfvn1KS0tTWlqa9u3bp5tvvllPPfVUScYLAACAcsqtAQmTJk3S3LlzFR39+9JH0dHRmj17tp588kmvBQcAAICKw63JRceOHVNeXsHP083Pz1dKSorHQQEAAJQnfHKRa9x6St27d9cDDzygnTt3OtqSkpL0l7/8RXFxcV4LDgAAoDywWC1e3yoitxLPxYsXKzIyUq1bt3Z87nqbNm0UERGhV1991dsxAgAAwAXz5s1TVFSUAgMD1bZtW23fvv2yx6enp+uvf/2ratWqJZvNphtuuEGrVq0qsfjc6moPDw/XqlWr9N1332nfvn2yWCxq3LixbrjhBm/HBwAAUPaVga72ZcuWKSEhQQsWLFDbtm01Z84c9ezZUwcOHFDNmjULHJ+Tk6PbbrtNNWvW1PLly1WnTh399NNPjhWLSoJbiecFN9xwgxo1aiSJZQQAAABK06xZsxQfH6+RI0dKkhYsWKCVK1dq8eLFGj9+fIHjFy9erLS0NH3xxRfy9/eXJEVFRZVojG6n52+99ZaaN2+uoKAgBQUFqUWLFnr77Yr3YfYAAABXUtpjPHNycpSUlOQ018ZqtSouLk5bt24t9JyPPvpIsbGx+utf/6qIiAg1a9ZMM2bMUH5+vkfP4nLcqnjOmjVLkyZN0ujRo9WhQwdJ0ubNm/Xggw/qxIkTGjdunFeDBAAAKMssFu93tWdnZys7O9up7cLcmkudOHFC+fn5ioiIcGqPiIjQ/v37C73+Dz/8oPXr12vYsGFatWqVvv/+ez300EPKzc3VlClTvPdGLuLWU5o7d67mz5+vZ599Vv3791f//v31j3/8Qy+//HKxPloTAAAAhUtMTFRoaKjTlpiY6LXr2+121axZUwsXLlRMTIzuuusuPfHEE1qwYIHX7nEpt9fxbN++fYH29u3b69ixYx4HBQAAUK6UwPJHEyZMUEJCglNbYdVOSapRo4b8/PwKrKeekpKiyMjIQs+pVauW/P395efn52hr0qSJkpOTlZOTo4CAAA/fQUFuVTyvv/56vf/++wXaly1b5phsBAAAAPfZbDaFhIQ4bUUlngEBAYqJidG6descbXa7XevWrVNsbGyh53To0EHff/+97Ha7o+27775TrVq1SiTplNyseE6bNk133XWXNm3a5BjjuWXLFq1bt67QhBQAAAAlKyEhQffcc49at26tNm3aaM6cOcrMzHTMch8+fLjq1Knj6K7/y1/+opdeekkPP/ywxowZo4MHD2rGjBkaO3ZsicXoVuI5cOBAbd++XbNmzdKHH34o6Xxpdvv27brpppu8GR8AAECZVxY+MvOuu+7S8ePHNXnyZCUnJ6tVq1ZavXq1Y8LRkSNHZL0ozrp162rNmjUaN26cWrRooTp16ujhhx/W3//+9xKL0WKMMcU5ITc3Vw888IAmTZqkBg0aeD2glf7RXr8mgPKnb+4Bx9fxM06WYiQAyopFE68p7RCKlP7saK9fM+zvL3n9mqWt2Om5v7+/VqxYURKxAAAAlEulvY5neeFWXXjAgAGOLnYAAADAFW6N8WzUqJGmT5+uLVu2KCYmRsHBwU77S3JQKgAAQJlTAgvIV0RuJZ6vvfaawsLClJSUpKSkJKd9FouFxBMAAFxVKmrXuLe5lXgePnzY8fWFuUkWCw8cAAAARXO7Lvzaa6+pWbNmCgwMVGBgoJo1a6ZXX33Vm7EBAACUD1ar97cKyK2K5+TJkzVr1iyNGTPGsRr+1q1bNW7cOB05ckTTp0/3apAAAABlGT2/rnEr8Zw/f74WLVqkIUOGONr69++vFi1aaMyYMSSeAAAAKMCtxDM3N1etW7cu0B4TE6O8vDyPgwIAAChXKmjXuLe59ZTuvvtuzZ8/v0D7woULNWzYMI+DAgAAQMXjVsVTOj+56L///a/atWsnSdq2bZuOHDmi4cOHKyEhwXHcrFmzPI8SAAAA5Z5biefevXt18803S5IOHTokSapRo4Zq1KihvXv3Oo5joC0AALgasI6na9xKPDds2ODtOAAAAFDBud3VDgAAgP+Pj8x0CU8JAAAAPkHFEwAAwFOM8XQJiScAAICHLHS1u4SnBAAAAJ+g4gkAAOAputpdQsUTAAAAPkHFEwAAwEMWPqvdJSSeAAAAnuLTGl1Ceg4AAACfIPEEAACAT9DVDgAA4CnGeLqEpwQAAACfoOIJAADgKSYXuYSKJwAAAHyCiicAAICHWMfTNSSeAAAAnrKQeLqCpwQAAACfoOIJAADgKSuTi1xBxRMAAAA+QcUTAADAQxbGeLqEpwQAAACfIPEEAACAT9DVDgAA4CkmF7mEiicAAAB8gsQTAADAUxar9zc3zJs3T1FRUQoMDFTbtm21fft2l8577733ZLFYNGDAALfu6yoSTwAAAE9ZLN7fimnZsmVKSEjQlClTtHPnTrVs2VI9e/ZUamrqZc/78ccf9dhjj6lTp07uvnuXkXgCAABUALNmzVJ8fLxGjhyppk2basGCBapcubIWL15c5Dn5+fkaNmyYpk2bpoYNG5Z4jCSeAAAAnrJavb5lZ2crIyPDacvOzi709jk5OUpKSlJcXNxFIVkVFxenrVu3Fhn29OnTVbNmTY0aNcrrj6QwJJ4AAACeKoExnomJiQoNDXXaEhMTC739iRMnlJ+fr4iICKf2iIgIJScnF3rO5s2b9dprr2nRokVefxxFYTklAACAMmjChAlKSEhwarPZbF659unTp3X33Xdr0aJFqlGjhleu6QoSTwAAAE+VwDqeNpvN5USzRo0a8vPzU0pKilN7SkqKIiMjCxx/6NAh/fjjj+rXr5+jzW63S5IqVaqkAwcO6LrrrvMg+sLR1Q4AAFDOBQQEKCYmRuvWrXO02e12rVu3TrGxsQWOb9y4sb7++mvt3r3bsfXv31/dunXT7t27Vbdu3RKJk4onAACAp9xcd9ObEhISdM8996h169Zq06aN5syZo8zMTI0cOVKSNHz4cNWpU0eJiYkKDAxUs2bNnM4PCwuTpALt3kTiCQAAUAHcddddOn78uCZPnqzk5GS1atVKq1evdkw4OnLkiKzW0k2QLcYYU6oRXGKlf3RphwCgDOibe8DxdfyMk6UYCYCyYtHEa0o7hCKd+/dLXr9m4B9Ge/2apY2KJwAAgKfc+KShq1HpD0gAAADAVYGKJwAAgKdKeexkeUHiCQAA4Cm62l1Ceg4AAACfoOIJAADgqTKwjmd5wFMCAACAT1DxBAAA8BSTi1xC4gkAAOApJhe5hPQcAAAAPkHFEwAAwFNMLnIJTwkAAAA+QeIJAAAAn6CrHQAAwFNMLnIJFU8AAAD4BBVPAAAAT7GOp0tIPAEAADxk6Gp3Cek5AAAAfIKKJwAAgKdYx9MlPCUAAAD4BBVPAAAAT1HxdAmJJwAAgIeYXOQa0nMAAAD4BIknAAAAfILEEwAAAD7BGE8AAABPMbnIJSSeAAAAnmJykUtIzwEAAOATVDwBAAA8ZaWW5woSTwAAAA+xjqdrSM8BAADgE1Q8AQAAPMWsdpfwlAAAAOATVDwBAAA8ZKh4uoTEEwAAwFNMLnIJ6TkAAAB8gsQTAAAAPkHiCQAAUEHMmzdPUVFRCgwMVNu2bbV9+/Yij120aJE6deqkatWqqVq1aoqLi7vs8d5A4gkAAOAhY7F6fSuuZcuWKSEhQVOmTNHOnTvVsmVL9ezZU6mpqYUe/9lnn2nIkCHasGGDtm7dqrp166pHjx46evSop4+jSBZjjCmxq7thpX90aYcAoAzom3vA8XX8jJOlGAmAsmLRxGtKO4Qind6xyuvXrHpLn2Id37ZtW91yyy166aWXJEl2u11169bVmDFjNH78+Cuen5+fr2rVqumll17S8OHD3Yr5Sqh4AgAAlEHZ2dnKyMhw2rKzsws9NicnR0lJSYqLi3O0Wa1WxcXFaevWrS7dLysrS7m5uapevbpX4i8MiScAAICnLFavb4mJiQoNDXXaEhMTC739iRMnlJ+fr4iICKf2iIgIJScnu/QW/v73v6t27dpOyau3sY4nAABAGTRhwgQlJCQ4tdlsthK518yZM/Xee+/ps88+U2BgYIncQyLxBAAA8JgpgQXkbTaby4lmjRo15Ofnp5SUFKf2lJQURUZGXvbc5557TjNnztSnn36qFi1auB2vK+hqBwAA8FQJdLUXR0BAgGJiYrRu3TpHm91u17p16xQbG1vkef/4xz/01FNPafXq1WrdurXbb99VVDwBAAAqgISEBN1zzz1q3bq12rRpozlz5igzM1MjR46UJA0fPlx16tRxjBN99tlnNXnyZC1dulRRUVGOsaBVqlRRlSpVSiRGEk8AAAAPGZX+Z7XfddddOn78uCZPnqzk5GS1atVKq1evdkw4OnLkiKzW3yup8+fPV05Oju68806n60yZMkVTp04tkRhJPAEAACqI0aNHa/To0YXu++yzz5xe//jjjyUf0CUY4wkAAACfoOIJAADgIXc+4vJqxFMCAACAT1DxBAAA8BQVT5eQeAIAAHioJBaQr4hIzwEAAOATVDwBAAA8xOQi1/CUAAAA4BMWY4wp7SAAAADKs7SvN3v9mtWbd/T6NUsbXe0AAAAeoqvdNTwlAAAA+ESZq3jGzzhZ2iEAKAMWTbzG8fVK/+hSjARAWdE390Bph1AkI5ZTcgUVTwAAAPgEiScAAAB8osx1tQMAAJQ3TC5yDU8JAAAAPkHFEwAAwFN8VrtLSDwBAAA8ZOhEdglPCQAAAD5BxRMAAMBDhq52l1DxBAAAgE9Q8QQAAPAQyym5hsQTAADAQ3xkpmtIzwEAAOATVDwBAAA8RFe7a3hKAAAA8AkSTwAAAPgEXe0AAAAeYh1P11DxBAAAgE9Q8QQAAPAQyym5hoonAAAAfIKKJwAAgIdYTsk1JJ4AAAAeoqvdNaTnAAAA8AkqngAAAB6iq901PCUAAAD4BBVPAAAADzHG0zVUPAEAACqIefPmKSoqSoGBgWrbtq22b99+2eM/+OADNW7cWIGBgWrevLlWrVpVovGReAIAAFQAy5YtU0JCgqZMmaKdO3eqZcuW6tmzp1JTUws9/osvvtCQIUM0atQo7dq1SwMGDNCAAQO0d+/eEovRYowxJXZ1N8TPOFnaIQAoAxZNvMbx9Ur/6FKMBEBZ0Tf3QGmHUKTDh773+jUbXHd9sY5v27atbrnlFr300kuSJLvdrrp162rMmDEaP358gePvuusuZWZm6uOPP3a0tWvXTq1atdKCBQs8C74IVDwBAAA8ZGTx+lYcOTk5SkpKUlxcnKPNarUqLi5OW7duLfScrVu3Oh0vST179izyeG9gchEAAEAZlJ2drezsbKc2m80mm81W4NgTJ04oPz9fERERTu0RERHav39/oddPTk4u9Pjk5GQPIy8aFU8AAAAPGYvF61tiYqJCQ0OdtsTExNJ+qx6h4gkAAFAGTZgwQQkJCU5thVU7JalGjRry8/NTSkqKU3tKSooiIyMLPScyMrJYx3sDFU8AAAAPGWPx+maz2RQSEuK0FZV4BgQEKCYmRuvWrXO02e12rVu3TrGxsYWeExsb63S8JK1du7bI472BiicAAICHTBmo5SUkJOiee+5R69at1aZNG82ZM0eZmZkaOXKkJGn48OGqU6eOo7v+4YcfVpcuXfT888+rb9++eu+99/Tll19q4cKFJRYjiScAAEAFcNddd+n48eOaPHmykpOT1apVK61evdoxgejIkSOyWn9PkNu3b6+lS5fqySef1MSJE9WoUSN9+OGHatasWYnFyDqeAMok1vEEcKmyvI7nd4eOeP2aN1xXz+vXLG2lXxcGAADAVYGudgAAAA8Vd8H3qxUVTwAAAPgEiScAAAB8gq52AAAAD9HV7hoqngAAAPAJKp4AAAAeouLpGhJPAAAADxlD4ukKutoBAADgE1Q8AQAAPERXu2tIPAEAADxE4ukautoBAADgE1Q8AQAAPETF0zVUPAEAAOATVDwBAAA8xHJKrqHiCQAAAJ8g8QQAAIBP0NUOAADgITuTi1xCxRMAAAA+QcUTAADAQyyn5BoSTwAAAA8xq901dLUDAADAJ6h4AgAAeIiudtdQ8QQAAIBPUPEEAADwEGM8XUPiCQAA4CG62l1DVzsAAAB8gsQTAAAAPkFXOwAAgIcY4+kaKp4AAADwCSqeAAAAHrKXdgDlBBVPAAAA+AQVTwAAAA8xxtM1JJ4AAAAeYh1P19DVDgAAAJ+g4gkAAOAhutpdQ8UTAAAAPkHFEwAAwEOM8XQNFU8AAAAP2Y33t5KSlpamYcOGKSQkRGFhYRo1apTOnDlz2ePHjBmj6OhoBQUFqV69eho7dqxOnTpV7HuTeAIAAFxFhg0bpm+++UZr167Vxx9/rE2bNun+++8v8vhff/1Vv/76q5577jnt3btXb7zxhlavXq1Ro0YV+94WY0wJ5tTFFz/jZGmHAKAMWDTxGsfXK/2jSzESAGVF39wDpR1CkTZ9k+n1a3a+Mdjr19y3b5+aNm2qHTt2qHXr1pKk1atXq0+fPvrll19Uu3Ztl67zwQcf6M9//rMyMzNVqZLrIzepeAIAAJRB2dnZysjIcNqys7M9uubWrVsVFhbmSDolKS4uTlarVdu2bXP5OqdOnVJISEixkk6JxBMAAMBjRhavb4mJiQoNDXXaEhMTPYozOTlZNWvWdGqrVKmSqlevruTkZJeuceLECT311FOX7Z4vCoknAACAh4yxeH2bMGGCTp065bRNmDCh0PuPHz9eFovlstv+/fs9fp8ZGRnq27evmjZtqqlTpxb7fJZTAgAAKINsNptsNptLxz766KMaMWLEZY9p2LChIiMjlZqa6tSel5entLQ0RUZGXvb806dPq1evXqpatar+9a9/yd/f36XYLkbiCQAA4KHSnqodHh6u8PDwKx4XGxur9PR0JSUlKSYmRpK0fv162e12tW3btsjzMjIy1LNnT9lsNn300UcKDAx0K0662gEAADxkl8XrW0lo0qSJevXqpfj4eG3fvl1btmzR6NGjNXjwYMeM9qNHj6px48bavn27pPNJZ48ePZSZmanXXntNGRkZSk5OVnJysvLz84t1fyqeAAAAV5ElS5Zo9OjR6t69u6xWqwYOHKgXX3zRsT83N1cHDhxQVlaWJGnnzp2OGe/XX3+907UOHz6sqKgol+9N4gkAAOAhY8rPR2ZWr15dS5cuLXJ/VFSULl7mvWvXrvLWsu90tQMAAMAnqHgCAAB4qLQnF5UXVDwBAADgEySeAAAA8Am62gEAADxkSmj5o4qGiicAAAB8goonAACAh+xMLnIJiScAAICHytM6nqWJrnYAAAD4BBVPAAAAD7GOp2uoeAIAAMAnqHgCAAB4yM5ySi4pdsXz2LFjeuedd7Rq1Srl5OQ47cvMzNT06dO9FhwAAEB5YIz3t4qoWInnjh071LRpU/31r3/VnXfeqRtvvFHffPONY/+ZM2c0bdo0rwcJAACA8q9YiefEiRN1xx136LffflNKSopuu+02denSRbt27Sqp+AAAAMo8Yyxe3yqiYo3xTEpK0rx582S1WlW1alW9/PLLqlevnrp37641a9aoXr16JRUnAAAAyrliTy46d+6c0+vx48erUqVK6tGjhxYvXuy1wAAAAFCxFCvxbNasmb744gu1aNHCqf2xxx6T3W7XkCFDvBocAABAecBHZrqmWGM8hw8fri1bthS6729/+5umTZtGdzsAAAAKZTGmbE3Yj59xsrRDAFAGLJp4jePrlf7RpRgJgLKib+6B0g6hSP/anu/1a97Rxs/r1yxtHi0gf/z4cR04cP6HIDo6WuHh4V4JCgAAoDwxLCDvErc+MjMzM1P33nuvateurc6dO6tz586qXbu2Ro0apaysLG/HCAAAgArArcQzISFBGzdu1EcffaT09HSlp6fr3//+tzZu3KhHH33U2zECAACUaXbj/a0icqurfcWKFVq+fLm6du3qaOvTp4+CgoI0aNAgzZ8/31vxAQAAoIJwK/HMyspSREREgfaaNWvS1Q4AAK46ZWuqdtnlVld7bGyspkyZ4rSY/NmzZzVt2jTFxsZ6LTgAAIDywBjvbxWRWxXPOXPmqFevXrr22mvVsmVLSdJXX32lwMBArVmzxqsBAgAAoGJwK/Fs3ry5Dh48qCVLlmj//v2SpCFDhmjYsGEKCgryaoAAAABlnd2wnJIr3Eo8N23apPbt2ys+Pt6pPS8vT5s2bVLnzp29EhwAAAAqDrfGeHbr1k1paWkF2k+dOqVu3bp5HBQAAAAqHrcqnsYYWSwFS8onT55UcHCwx0EBAACUJxV1MpC3FSvx/OMf/yhJslgsGjFihGw2m2Nffn6+9uzZo/bt23s3QgAAAFQIxUo8Q0NDJZ2veFatWtVpIlFAQIDatWtXYNwnAABARUfF0zXFSjxff/11SVJUVJQef/xxVa5cuUSCAgAAKE8q6kdceptbk4uGDx+uo0ePFmg/ePCgfvzxR09jAgAAQAXkVuI5YsQIffHFFwXat23bphEjRngaEwAAQLlijMXrW0XkVuK5a9cudejQoUB7u3bttHv3bk9jAgAAQAXk1nJKFotFp0+fLtB+6tQp5efnexwUKp7+nYPUqVWgKtss+v6XXC1ZnanU3+xFHp/4UJhqhPkVaN+QdE5L12RKkv7cO1hNovwVVsWq7FyjQ7/kacWGTCWfLPq6AMqP6h1bq+GjoxR6czMF1q6pLwc+pJSP1pV2WEChytPkorS0NI0ZM0b/+c9/ZLVaNXDgQL3wwguqUqXKFc81xqhPnz5avXq1/vWvf2nAgAHFurdbiWfnzp2VmJiod999V35+55OD/Px8JSYmqmPHju5cEhVYr3aB6t46UIv/c0Yn0u0a0KWyHhkcoskL05VXxP9TnnnjlKwX9TLUCa+khKEh+nJftqPtp2N52rY3W2kZdgUHWtSv0/nrTng5vVz9AgBQOL/gysrYc0A/v7FCrZfPK+1wgMsqT5OLhg0bpmPHjmnt2rXKzc3VyJEjdf/992vp0qVXPHfOnDmFruXuKrcSz2effVadO3dWdHS0OnXqJEn6/PPPlZGRofXr17sdDCqm7m2CtHLLWX11MFeStPg/Z/T8w9V0U3SAdnybU+g5Z7Kc/wb3jvVXalq+vjuS52j7fPfvSejJU9KHG7M0NT5MNUKtOp5O1RMo746v2aTjazaVdhhAhbJv3z6tXr1aO3bsUOvWrSVJc+fOVZ8+ffTcc8+pdu3aRZ67e/duPf/88/ryyy9Vq1Ytt+7v1hjPpk2bas+ePRo0aJBSU1N1+vRpDR8+XPv371ezZs3cCgQVU40wq8KqWLXvcK6j7Wy20Q+/5qlhHdf+3+Nnldo2s2nLnuwijwnwlzq0tOn4b/lKyyDpBACgMFu3blVYWJgj6ZSkuLg4Wa1Wbdu2rcjzsrKyNHToUM2bN0+RkZFu39+tiqck1a5dWzNmzHD7xrg6hAaf/79NRqZzMng60+7YdyU3RQeocqBFW/acK7Cv6802Dbw1WIEBFh07ma/Z72Yon7wTAFABZGdnKzvbuehis9mcPjmyuJKTk1WzZk2ntkqVKql69epKTk4u8rxx48apffv2+sMf/uD2vSU3E89Nmy7f9dG5c+fL7i+JB4myoe2NAfpz798HJ899P8Pja3ZsadPeQ7k6dabgAJpt3+To28O5Cq1iVY+2QXrgjqqa+dapIseOAgBQEkpibkFiYqKmTZvm1DZlyhRNnTq1wLHjx4/Xs88+e9nr7du3z604PvroI61fv167du1y6/yLuZV4du3atUDbxQNNrzSzvTgPEuXL7oM5+uHXdMdrf7/zPxchwVadyvz956JqsFU/p+RdenoB1UOsahLlr5dXFFxFQTrfbX822yj1N7t+OHpaLyRU183RAdpexNhRAABKQkkknhMmTFBCQoJTW1FFukcfffSKa6k3bNhQkZGRSk1NdWrPy8tTWlpakV3o69ev16FDhxQWFubUPnDgQHXq1EmfffbZZe97MbcSz99++83pdW5urnbt2qVJkybpmWeeueL5xXmQKF+yc6TjOc593eln7Goc5a+fU88nnoEBFjWsXUkbdxbsOr9Uh5Y2ZWQZff197hWPtVgkWaRKfhVz0V0AwNWlOL3B4eHhCg8Pv+JxsbGxSk9PV1JSkmJiYiSdTyztdrvatm1b6Dnjx4/Xfffd59TWvHlzzZ49W/369XMpvgvcSjxDQ0MLtN12220KCAhQQkKCkpKSLns+3epXl3Xbz6pvhyCl/pavE+l2/aFzZaWftmvXgd+rkglDQ7TrQI42JP2ejFokdWhh09Y92QWWqagRZtUtTQL0zeFcnckyqlbVql6xQcrNNfr6ENVOoCLwC66s4OvrOV5XbnCtQlo2Vk7aKZ37+VgpRgYUVF6WU2rSpIl69eql+Ph4LViwQLm5uRo9erQGDx7smNF+9OhRde/eXW+99ZbatGmjyMjIQquh9erVU4MGDYp1f7cnFxUmIiJCBw4c8OYlUQGs/t85BQRYdHfvKqocaNHBn3P1wrIMp3GY4WFWVansXKls0sBf14T6FTqpKDfPqFFdf8W1CVLlQIsyMu06eCRPM986pdNZ5eRvP4DLCo1ppth1bzteN31uoiTp57f+T3tGTSitsIByb8mSJRo9erS6d+/uWED+xRdfdOzPzc3VgQMHlJWV5fV7W4wp/qiEPXv2OL02xujYsWOaOXOm8vLytHnzZrcDip9x0u1zAVQciyZe4/h6pX90KUYCoKzom1t2i1uLPvX+NePjvH/N0uZWxbNVq1ayWCy6NGdt166dFi9e7JXAAAAAygs7S/m5xK3E8/Dhw06vrVarwsPDFRgY6JWgAAAAUPG4lXjWr1/f23EAAACUWyWxnFJF5HLiefGg0ysZO3asW8EAAACURySernE58Zw9e7bT6+PHjysrK8uxmGh6eroqV66smjVrkngCAACgANc+LFvnx3Ve2J555hm1atVK+/btU1pamtLS0rRv3z7dfPPNeuqpp0oyXgAAAJRTLieeF5s0aZLmzp2r6OjflziJjo7W7Nmz9eSTT3otOAAAAFQcbk0uOnbsmPLyCn7Odn5+vlJSUjwOCgAAoDwpL59cVNrcqnh2795dDzzwgHbu3OloS0pK0l/+8hfFxVXA1U4BAAAuwxjj9a0icivxXLx4sSIjI9W6dWvH5663adNGERERevXVV70dIwAAACoAt7raw8PDtWrVKn333Xfat2+fLBaLGjdurBtuuMHb8QEAAJR5FbRA6XVuJZ4X3HDDDWrUqJEkyWKxeCUgAAAAVExudbVL0ltvvaXmzZsrKChIQUFBatGihd5++21vxgYAAFAu2O3e3yoityqes2bN0qRJkzR69Gh16NBBkrR582Y9+OCDOnHihMaNG+fVIAEAAMoyutpd41biOXfuXM2fP1/Dhw93tPXv31833nijpk6dSuIJAACAAtxex7N9+/YF2tu3b69jx455HBQAAEB5wjqernFrjOf111+v999/v0D7smXLHJONAAAAgIu5VfGcNm2a7rrrLm3atMkxxnPLli1at25doQkpAAAA4FbiOXDgQG3fvl2zZs3Shx9+KElq0qSJtm/frptuusmb8QEAAJR5TC5yTbETz9zcXD3wwAOaNGmS3nnnnZKICQAAABVQscd4+vv7a8WKFSURCwAAQLlk7MbrW0Xk1uSiAQMGOLrYAQAArnZ24/2tInJrjGejRo00ffp0bdmyRTExMQoODnbaP3bsWK8EBwAAgIrDrcTztddeU1hYmJKSkpSUlOS0z2KxkHgCAICrCpOLXONW4nn48GHH1+b/P2mLxeKdiAAAAFAhuTXGUzpf9WzWrJkCAwMVGBioZs2a6dVXX/VmbAAAAOWC3W68vlVEblU8J0+erFmzZmnMmDGKjY2VJG3dulXjxo3TkSNHNH36dK8GCQAAUJbR1e4atxLP+fPna9GiRRoyZIijrX///mrRooXGjBlD4gkAAIAC3Eo8c3Nz1bp16wLtMTExysvL8zgoAACA8oSKp2vcGuN59913a/78+QXaFy5cqGHDhnkcFAAAACoetyqe0vnJRf/973/Vrl07SdK2bdt05MgRDR8+XAkJCY7jZs2a5XmUAAAAKPfcSjz37t2rm2++WZJ06NAhSVKNGjVUo0YN7d2713EcSywBAICrgZ2+dpe4lXhu2LDB23EAAACggnO7qx0AAADnGXtpR1A+uL2APAAAAFAcVDwBAAA8ZBjj6RISTwAAAA/Z6Wp3CV3tAAAA8AkSTwAAAA8ZY7y+lZS0tDQNGzZMISEhCgsL06hRo3TmzJkrnrd161bdeuutCg4OVkhIiDp37qyzZ88W694kngAAAB6yG+9vJWXYsGH65ptvtHbtWn388cfatGmT7r///sues3XrVvXq1Us9evTQ9u3btWPHDo0ePVpWa/FSScZ4AgAAXCX27dun1atXa8eOHWrdurUkae7cuerTp4+ee+451a5du9Dzxo0bp7Fjx2r8+PGOtujo6GLfn4onAACAh4zdeH3Lzs5WRkaG05adne1RnFu3blVYWJgj6ZSkuLg4Wa1Wbdu2rdBzUlNTtW3bNtWsWVPt27dXRESEunTpos2bNxf7/iSeAAAAZVBiYqJCQ0OdtsTERI+umZycrJo1azq1VapUSdWrV1dycnKh5/zwww+SpKlTpyo+Pl6rV6/WzTffrO7du+vgwYPFuj+JJwAAQBk0YcIEnTp1ymmbMGFCoceOHz9eFovlstv+/fvdisP+/9eKeuCBBzRy5EjddNNNmj17tqKjo7V48eJiXYsxngAAAB4qiUnoNptNNpvNpWMfffRRjRgx4rLHNGzYUJGRkUpNTXVqz8vLU1pamiIjIws9r1atWpKkpk2bOrU3adJER44ccSm+C0g8AQAAyrnw8HCFh4df8bjY2Filp6crKSlJMTExkqT169fLbrerbdu2hZ4TFRWl2rVr68CBA07t3333nXr37l2sOOlqBwAA8JDdbry+lYQmTZqoV69eio+P1/bt27VlyxaNHj1agwcPdsxoP3r0qBo3bqzt27dLkiwWix5//HG9+OKLWr58ub7//ntNmjRJ+/fv16hRo4p1fyqeAAAAV5ElS5Zo9OjR6t69u6xWqwYOHKgXX3zRsT83N1cHDhxQVlaWo+2RRx7RuXPnNG7cOKWlpally5Zau3atrrvuumLdm8QTAADAQyX5SUPeVr16dS1durTI/VFRUYW+n/Hjxzut4+kOEk8AAAAPGXtpR1A+MMYTAAAAPkHFEwAAwEP2ctTVXpqoeAIAAMAnqHgCAAB4qDxNLipNVDwBAADgEySeAAAA8Am62gEAADxUUp80VNFQ8QQAAIBPUPEEAADwEHOLXEPiCQAA4CFDV7tL6GoHAACAT1DxBAAA8BCfXOQaEk8AAAAP0dXuGrraAQAA4BNUPAEAADxExdM1VDwBAADgE1Q8AQAAPETB0zVUPAEAAOATJJ4AAADwCbraAQAAPMTkItdQ8QQAAIBPUPEEAADwkOGTi1xC4gkAAOAhO13tLqGrHQAAAD5BxRMAAMBDiyZeU9ohlAtUPAEAAOATJJ4AAADwCRJPAAAA+ASJJwAAAHyCxBMAAAA+QeIJAAAAnyDxBAAAgE+QeAIAAMAnSDwBAADgEySeAAAA8AkSTwAAAPgEiScAAAB8gsQTAAAAPkHiCQAAAJ8g8QQAAIBPkHgCAADAJ0g8AQAA4BMkngAAAPAJEk8AAAD4BIknAAAAfILEEwAAAD5B4gkAAACfIPEEAACAT5B4AgAAwCdIPAEAAOATJJ4AAADwCRJPAAAA+ASJJwAAAHyCxBMAAAA+QeIJAAAAnyDxBAAAgE+QeAIAAMAnSDwBAADgEySeAAAA8AkSTwAAAPgEiScAAAB8gsQTAAAAPkHiCQAAAJ8g8QQAAIBPkHgCAADAJ0g8AQAA4BMkngAAAPAJEk8AAAD4BIknAAAAfILEEwAAAD5B4gkAAACfIPEEAACAT5B4AgAAwCdIPAEAAOATJJ4AAADwCYsxxpR2EAAAAKj4qHiiTMnOztbUqVOVnZ1d2qEAKCP4vQBUHFQ8UaZkZGQoNDRUp06dUkhISGmHA6AM4PcCUHFQ8QQAAIBPkHgCAADAJ0g8AQAA4BMknihTbDabpkyZIpvNVtqhACgj+L0AVBxMLgIAAIBPUPEEAACAT5B4AgAAwCdIPAEAAOATJJ7wuaioKM2ZM6e0wwBQhvB7Abg6kHii3BsxYoQGDBhQ7PO++eYbDRw4UFFRUbJYLPyjB1Qg7v5eWLRokTp16qRq1aqpWrVqiouL0/bt270fIHCVIvGEW3Jycko7BI9lZWWpYcOGmjlzpiIjI0s7HKDcqwi/Fz777DMNGTJEGzZs0NatW1W3bl316NFDR48eLe3QgAqBxBOSpK5du2r06NEaPXq0QkNDVaNGDU2aNEkXVtuKiorSU089peHDhyskJET333+/JGnFihW68cYbZbPZFBUVpeeff97puqmpqerXr5+CgoLUoEEDLVmyxGn/jz/+KIvFot27dzva0tPTZbFY9NlnnznavvnmG91+++0KCQlR1apV1alTJx06dEhTp07Vm2++qX//+9+yWCxO53399de69dZbFRQUpGuuuUb333+/zpw547jmLbfcon/+858aPHgw6wMChbgafy8sWbJEDz30kFq1aqXGjRvr1Vdfld1u17p167z4ZIGrF4knHN58801VqlRJ27dv1wsvvKBZs2bp1Vdfdex/7rnn1LJlS+3atUuTJk1SUlKSBg0apMGDB+vrr7/W1KlTNWnSJL3xxhuOc0aMGKGff/5ZGzZs0PLly/Xyyy8rNTW1WHEdPXpUnTt3ls1m0/r165WUlKR7771XeXl5euyxxzRo0CD16tVLx44d07Fjx9S+fXtlZmaqZ8+eqlatmnbs2KEPPvhAn376qUaPHu2txwVcFa723wtZWVnKzc1V9erVi/3sABTCAMaYLl26mCZNmhi73e5o+/vf/26aNGlijDGmfv36ZsCAAU7nDB061Nx2221ObY8//rhp2rSpMcaYAwcOGElm+/btjv379u0zkszs2bONMcYcPnzYSDK7du1yHPPbb78ZSWbDhg3GGGMmTJhgGjRoYHJycgqN/Z577jF/+MMfnNoWLlxoqlWrZs6cOeNoW7lypbFarSY5ObnANerXr++ICcB5V/vvBWOM+ctf/mIaNmxozp49W+h+AMVDxRMO7dq1k8VicbyOjY3VwYMHlZ+fL0lq3bq10/H79u1Thw4dnNo6dOjgOGffvn2qVKmSYmJiHPsbN26ssLCwYsW1e/duderUSf7+/i6fs2/fPrVs2VLBwcFOsdntdh04cKBY9weuZlfz74WZM2fqvffe07/+9S8FBgYWKz4AhatU2gGg/Lj4l7W3WK3n/+9jLvrk1tzcXKdjgoKCvH5fAN5RUX8vPPfcc5o5c6Y+/fRTtWjRokTvBVxNqHjCYdu2bU6v//e//6lRo0by8/Mr9PgmTZpoy5YtTm1btmzRDTfcID8/PzVu3Fh5eXlKSkpy7D9w4IDS09Mdr8PDwyVJx44dc7RdPKFAklq0aKHPP/+8wD88FwQEBDiqLxfH9tVXXykzM9MpNqvVqujo6EKvA6Cgq/H3wj/+8Q899dRTWr16dYGKLgAPlXZfP8qGLl26mCpVqphx48aZ/fv3m6VLl5rg4GCzYMECY0zhYyCTkpKM1Wo106dPNwcOHDBvvPGGCQoKMq+//rrjmF69epmbbrrJ/O9//zNffvml6dixowkKCnK6Vrt27UynTp3Mt99+az777DPTpk0bp7FcJ06cMNdcc4354x//aHbs2GG+++4789Zbb5n9+/cbY4x55plnTL169cz+/fvN8ePHTU5OjsnMzDS1atUyAwcONF9//bVZv369adiwobnnnnsc983Ozja7du0yu3btMrVq1TKPPfaY2bVrlzl48GBJPGKg3Lkafy/MnDnTBAQEmOXLl5tjx445ttOnT5fEIwauOiSeMMac/wfmoYceMg8++KAJCQkx1apVMxMnTnRMKihq8s3y5ctN06ZNjb+/v6lXr5755z//6bT/2LFjpm/fvsZms5l69eqZt956q8C1vv32WxMbG2uCgoJMq1atzH//+1+nf2CMMearr74yPXr0MJUrVzZVq1Y1nTp1MocOHTLGGJOammpuu+02U6VKFafz9uzZY7p162YCAwNN9erVTXx8vNM/HhcmMFy6denSxSvPFCjvrsbfC/Xr1y/098KUKVO88kyBq53FmIsG0eCq1bVrV7Vq1YpP7wHgwO8FAN7GGE8AAAD4BIknAAAAfIKudgAAAPgEFU8AAAD4BIknAAAAfILEEwAAAD5B4gkAAACfIPEEAACAT5B4AgAAwCdIPAEAAOATJJ4AAADwCRJPAAAA+MT/Ay8Wkt8lBwhAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VERIFICACIÓN DE ESTACIONARIEDAD - DATOS ORIGINALES\n",
      "============================================================\n",
      "\n",
      "Producto 1:\n",
      "  Estadístico ADF: -0.8594\n",
      "  p-value: 0.8010\n",
      "  Valores críticos:\n",
      "    1%: -3.4847\n",
      "    5%: -2.8853\n",
      "    10%: -2.5795\n",
      "  ✗ Serie NO es estacionaria (p-value > 0.05)\n",
      "\n",
      "Producto 2:\n",
      "  Estadístico ADF: -2.0330\n",
      "  p-value: 0.2723\n",
      "  Valores críticos:\n",
      "    1%: -3.4842\n",
      "    5%: -2.8851\n",
      "    10%: -2.5794\n",
      "  ✗ Serie NO es estacionaria (p-value > 0.05)\n",
      "\n",
      "⚠️ Advertencia: Una o ambas series no son estacionarias.\n",
      "VAR requiere series estacionarias. Se aplicará diferenciación.\n"
     ]
    }
   ],
   "source": [
    "# Función para verificar estacionariedad\n",
    "def check_stationarity(series, name):\n",
    "    \"\"\"\n",
    "    Realiza prueba de Dickey-Fuller aumentada para verificar estacionariedad.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pandas.Series\n",
    "        Serie temporal a verificar\n",
    "    name : str\n",
    "        Nombre de la serie para el reporte\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool\n",
    "        True si la serie es estacionaria, False en caso contrario\n",
    "    \"\"\"\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Estadístico ADF: {result[0]:.4f}\")\n",
    "    print(f\"  p-value: {result[1]:.4f}\")\n",
    "    print(f\"  Valores críticos:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"    {key}: {value:.4f}\")\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(f\"  ✓ Serie es estacionaria (p-value <= 0.05)\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"  ✗ Serie NO es estacionaria (p-value > 0.05)\")\n",
    "        return False\n",
    "\n",
    "# Análisis de correlación entre las series\n",
    "print(\"=\" * 60)\n",
    "print(\"ANÁLISIS DE CORRELACIÓN ENTRE SERIES\")\n",
    "print(\"=\" * 60)\n",
    "correlation = df.corr()\n",
    "print(\"\\nMatriz de correlación:\")\n",
    "print(correlation)\n",
    "print(f\"\\nCorrelación entre producto1 y producto2: {correlation.loc['producto1', 'producto2']:.4f}\")\n",
    "\n",
    "# Visualización de correlación\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlación entre Productos')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Verificación de estacionariedad de los datos originales\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICACIÓN DE ESTACIONARIEDAD - DATOS ORIGINALES\")\n",
    "print(\"=\" * 60)\n",
    "stationary_p1 = check_stationarity(df['producto1'], 'Producto 1')\n",
    "stationary_p2 = check_stationarity(df['producto2'], 'Producto 2')\n",
    "\n",
    "if not stationary_p1 or not stationary_p2:\n",
    "    print(\"\\n⚠️ Advertencia: Una o ambas series no son estacionarias.\")\n",
    "    print(\"VAR requiere series estacionarias. Se aplicará diferenciación.\")\n",
    "else:\n",
    "    print(\"\\n✓ Ambas series son estacionarias. No se requiere diferenciación.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34830eb3",
   "metadata": {},
   "source": [
    "## Aplicación de Diferenciación\n",
    "\n",
    "Como las series no son estacionarias, aplicamos diferenciación para hacerlas estacionarias antes de aplicar el modelo VAR. La diferenciación ayuda a eliminar tendencias y hacer las series más estables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03a8acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APLICACIÓN DE DIFERENCIACIÓN\n",
      "============================================================\n",
      "\n",
      "Datos originales: 127 observaciones\n",
      "Datos diferenciados (primera diferenciación): 126 observaciones\n",
      "\n",
      "Primeras filas de datos diferenciados:\n",
      "   producto1  producto2\n",
      "2  -2.599107  10.686220\n",
      "3 -18.795576  11.332365\n",
      "4   7.848808  11.902406\n",
      "5  -6.758448   4.481108\n",
      "6  -5.473185   9.221717\n",
      "\n",
      "============================================================\n",
      "VERIFICACIÓN DE ESTACIONARIEDAD DESPUÉS DE PRIMERA DIFERENCIACIÓN\n",
      "============================================================\n",
      "\n",
      "Producto 1 (diferenciado):\n",
      "  Estadístico ADF: -2.7659\n",
      "  p-value: 0.0633\n",
      "  Valores críticos:\n",
      "    1%: -3.4847\n",
      "    5%: -2.8853\n",
      "    10%: -2.5795\n",
      "  ✗ Serie NO es estacionaria (p-value > 0.05)\n",
      "\n",
      "Producto 2 (diferenciado):\n",
      "  Estadístico ADF: -3.3572\n",
      "  p-value: 0.0125\n",
      "  Valores críticos:\n",
      "    1%: -3.4842\n",
      "    5%: -2.8851\n",
      "    10%: -2.5794\n",
      "  ✓ Serie es estacionaria (p-value <= 0.05)\n",
      "\n",
      "⚠️ Advertencia: Una o ambas series diferenciadas aún no son estacionarias.\n",
      "Aplicando segunda diferenciación...\n",
      "\n",
      "Datos con doble diferenciación: 125 observaciones\n",
      "\n",
      "============================================================\n",
      "VERIFICACIÓN DE ESTACIONARIEDAD DESPUÉS DE SEGUNDA DIFERENCIACIÓN\n",
      "============================================================\n",
      "\n",
      "Producto 1 (doble diferenciado):\n",
      "  Estadístico ADF: -15.1108\n",
      "  p-value: 0.0000\n",
      "  Valores críticos:\n",
      "    1%: -3.4847\n",
      "    5%: -2.8853\n",
      "    10%: -2.5795\n",
      "  ✓ Serie es estacionaria (p-value <= 0.05)\n",
      "\n",
      "Producto 2 (doble diferenciado):\n",
      "  Estadístico ADF: -53.6177\n",
      "  p-value: 0.0000\n",
      "  Valores críticos:\n",
      "    1%: -3.4842\n",
      "    5%: -2.8851\n",
      "    10%: -2.5794\n",
      "  ✓ Serie es estacionaria (p-value <= 0.05)\n",
      "\n",
      "✓ Ambas series con doble diferenciación son estacionarias.\n",
      "\n",
      "============================================================\n",
      "RESUMEN DE DIFERENCIACIÓN\n",
      "============================================================\n",
      "Orden de diferenciación aplicado: 2\n",
      "Usaremos datos diferenciados: True\n",
      "Datos originales: 127 observaciones\n",
      "Datos diferenciados: 125 observaciones\n",
      "\n",
      "✓ Los datos diferenciados se usarán para entrenar el modelo VAR.\n"
     ]
    }
   ],
   "source": [
    "# Aplicar diferenciación para hacer las series estacionarias\n",
    "print(\"=\" * 60)\n",
    "print(\"APLICACIÓN DE DIFERENCIACIÓN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Guardar los datos originales\n",
    "df_original = df.copy()\n",
    "\n",
    "# Aplicar primera diferenciación\n",
    "df_diff = df.diff().dropna()\n",
    "\n",
    "print(f\"\\nDatos originales: {len(df_original)} observaciones\")\n",
    "print(f\"Datos diferenciados (primera diferenciación): {len(df_diff)} observaciones\")\n",
    "print(f\"\\nPrimeras filas de datos diferenciados:\")\n",
    "print(df_diff.head())\n",
    "\n",
    "# Verificar estacionariedad después de la primera diferenciación\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICACIÓN DE ESTACIONARIEDAD DESPUÉS DE PRIMERA DIFERENCIACIÓN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stationary_p1_diff = check_stationarity(df_diff['producto1'], 'Producto 1 (diferenciado)')\n",
    "stationary_p2_diff = check_stationarity(df_diff['producto2'], 'Producto 2 (diferenciado)')\n",
    "\n",
    "# Inicializar variables\n",
    "USE_DIFFERENCED_DATA = True\n",
    "DIFF_ORDER = 1\n",
    "\n",
    "if stationary_p1_diff and stationary_p2_diff:\n",
    "    print(\"\\n✓ Ambas series diferenciadas son estacionarias. Proceder con VAR.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Advertencia: Una o ambas series diferenciadas aún no son estacionarias.\")\n",
    "    print(\"Aplicando segunda diferenciación...\")\n",
    "    \n",
    "    # Aplicar segunda diferenciación\n",
    "    df_diff = df_diff.diff().dropna()\n",
    "    DIFF_ORDER = 2\n",
    "    print(f\"\\nDatos con doble diferenciación: {len(df_diff)} observaciones\")\n",
    "    \n",
    "    # Verificar estacionariedad después de la segunda diferenciación\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"VERIFICACIÓN DE ESTACIONARIEDAD DESPUÉS DE SEGUNDA DIFERENCIACIÓN\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    stationary_p1_diff2 = check_stationarity(df_diff['producto1'], 'Producto 1 (doble diferenciado)')\n",
    "    stationary_p2_diff2 = check_stationarity(df_diff['producto2'], 'Producto 2 (doble diferenciado)')\n",
    "    \n",
    "    if stationary_p1_diff2 and stationary_p2_diff2:\n",
    "        print(\"\\n✓ Ambas series con doble diferenciación son estacionarias.\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Continuando con datos diferenciados aunque no sean completamente estacionarios.\")\n",
    "\n",
    "# Resumen final\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN DE DIFERENCIACIÓN\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Orden de diferenciación aplicado: {DIFF_ORDER}\")\n",
    "print(f\"Usaremos datos diferenciados: {USE_DIFFERENCED_DATA}\")\n",
    "print(f\"Datos originales: {len(df_original)} observaciones\")\n",
    "print(f\"Datos diferenciados: {len(df_diff)} observaciones\")\n",
    "print(f\"\\n✓ Los datos diferenciados se usarán para entrenar el modelo VAR.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f54f2d",
   "metadata": {},
   "source": [
    "## Función VAR\n",
    "\n",
    "Implementación del modelo VAR que permite especificar el orden del modelo:\n",
    "- **order**: Orden del modelo VAR (número de lags a incluir)\n",
    "- El modelo predice ambas series simultáneamente considerando sus interdependencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b152c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_forecast(data, order, forecast_horizon=1, use_differenced=True, diff_order=1, original_last_values=None):\n",
    "    \"\"\"\n",
    "    Calcula el modelo VAR y realiza predicciones para ambas series.\n",
    "    Si se usan datos diferenciados, revierte la diferenciación en las predicciones.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame con las series temporales (debe tener columnas producto1 y producto2)\n",
    "    order : int\n",
    "        Orden del modelo VAR (número de lags)\n",
    "    forecast_horizon : int\n",
    "        Número de períodos a predecir (por defecto 1)\n",
    "    use_differenced : bool\n",
    "        Si True, los datos están diferenciados y se debe revertir la diferenciación\n",
    "    diff_order : int\n",
    "        Orden de diferenciación aplicado (1 o 2)\n",
    "    original_last_values : array-like, optional\n",
    "        Últimos valores originales antes de la diferenciación (necesario para revertir)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Array de predicciones con forma (forecast_horizon, n_series)\n",
    "        Primera columna: producto1, Segunda columna: producto2\n",
    "        Si use_differenced=True, las predicciones están en la escala original\n",
    "    \"\"\"\n",
    "    if len(data) < order + 1:\n",
    "        # Si no hay suficientes datos, devolver el último valor observado\n",
    "        if use_differenced and original_last_values is not None:\n",
    "            # Si usamos datos diferenciados, devolver los valores originales\n",
    "            return np.tile(original_last_values, (forecast_horizon, 1))\n",
    "        else:\n",
    "            last_values = data.iloc[-1].values\n",
    "            return np.tile(last_values, (forecast_horizon, 1))\n",
    "    \n",
    "    try:\n",
    "        # Asegurar que los datos están en el formato correcto\n",
    "        data_clean = data.copy()\n",
    "        \n",
    "        # Crear y ajustar el modelo VAR\n",
    "        model = VAR(data_clean)\n",
    "        fit = model.fit(maxlags=order, ic='aic')\n",
    "        \n",
    "        # Realizar predicción en datos diferenciados\n",
    "        forecast_diff = fit.forecast(data_clean.values[-order:], steps=forecast_horizon)\n",
    "        \n",
    "        # Si usamos datos diferenciados, revertir la diferenciación\n",
    "        if use_differenced and original_last_values is not None:\n",
    "            forecast_original = np.zeros_like(forecast_diff)\n",
    "            \n",
    "            if diff_order == 1:\n",
    "                # Revertir primera diferenciación: y_t = y_{t-1} + diff_t\n",
    "                for i in range(forecast_horizon):\n",
    "                    if i == 0:\n",
    "                        forecast_original[i] = original_last_values + forecast_diff[i]\n",
    "                    else:\n",
    "                        forecast_original[i] = forecast_original[i-1] + forecast_diff[i]\n",
    "            elif diff_order == 2:\n",
    "                # Revertir doble diferenciación\n",
    "                # Necesitamos los dos últimos valores originales\n",
    "                # Para simplificar, usamos el último valor dos veces\n",
    "                last_val = original_last_values\n",
    "                prev_val = original_last_values  # Aproximación\n",
    "                \n",
    "                for i in range(forecast_horizon):\n",
    "                    if i == 0:\n",
    "                        # Primera reversión: diff1_t = y_t - y_{t-1}\n",
    "                        diff1 = last_val - prev_val\n",
    "                        # Segunda reversión: y_t = y_{t-1} + diff1_t + diff2_t\n",
    "                        forecast_original[i] = last_val + diff1 + forecast_diff[i]\n",
    "                    else:\n",
    "                        # Para pasos siguientes\n",
    "                        diff1_prev = forecast_original[i-1] - last_val if i == 1 else forecast_original[i-1] - forecast_original[i-2]\n",
    "                        forecast_original[i] = forecast_original[i-1] + diff1_prev + forecast_diff[i]\n",
    "            \n",
    "            return forecast_original\n",
    "        else:\n",
    "            # Si no usamos diferenciación, devolver predicción directa\n",
    "            return forecast_diff\n",
    "        \n",
    "    except Exception as e:\n",
    "        # En caso de error, usar el último valor como predicción\n",
    "        if use_differenced and original_last_values is not None:\n",
    "            return np.tile(original_last_values, (forecast_horizon, 1))\n",
    "        else:\n",
    "            last_values = data.iloc[-1].values\n",
    "            return np.tile(last_values, (forecast_horizon, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71358aba",
   "metadata": {},
   "source": [
    "## Función 1: Walk-Forward Validation\n",
    "    \n",
    "En Walk-Forward Validation, se entrena el modelo con datos hasta un punto específico y se valida con el siguiente punto. Luego se avanza un paso y se repite el proceso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "135691da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_validation(dataset, order, train_size_min=24, use_differenced=True, diff_order=1, original_dataset=None):\n",
    "    \"\"\"\n",
    "    Realiza validación Walk-Forward para el modelo VAR multivariado.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : pandas.DataFrame\n",
    "        Dataset con las columnas de productos (producto1 y producto2) - datos diferenciados\n",
    "    order : int\n",
    "        Orden del modelo VAR\n",
    "    train_size_min : int\n",
    "        Tamaño mínimo de entrenamiento antes de comenzar la validación (por defecto 24)\n",
    "    use_differenced : bool\n",
    "        Si True, los datos están diferenciados\n",
    "    diff_order : int\n",
    "        Orden de diferenciación aplicado\n",
    "    original_dataset : pandas.DataFrame, optional\n",
    "        Dataset original antes de diferenciación (necesario para obtener valores reales)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con métricas para cada producto:\n",
    "        - 'producto1': lista de diccionarios con métricas por iteración\n",
    "        - 'producto2': lista de diccionarios con métricas por iteración\n",
    "        Cada diccionario contiene: iteracion, ventana, rmse, mae\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    n = len(dataset)\n",
    "    \n",
    "    # Inicializar listas de métricas para cada producto\n",
    "    metrics_list_p1 = []\n",
    "    metrics_list_p2 = []\n",
    "    \n",
    "    print(f\"\\n=== Walk-Forward Validation para Modelo VAR (orden={order}) ===\")\n",
    "    \n",
    "    # Comenzar validación desde train_size_min hasta n-1\n",
    "    for i in range(train_size_min, n):\n",
    "        # Datos de entrenamiento: desde el inicio hasta i\n",
    "        train_data = dataset.iloc[:i]\n",
    "        # Datos de validación: i (en escala original si usamos diferenciación)\n",
    "        if use_differenced and original_dataset is not None:\n",
    "            # El índice i en datos diferenciados corresponde a i+diff_order en datos originales\n",
    "            actual_idx = i + diff_order\n",
    "            if actual_idx < len(original_dataset):\n",
    "                actual = original_dataset.iloc[actual_idx].values\n",
    "            else:\n",
    "                actual = original_dataset.iloc[-1].values\n",
    "        else:\n",
    "            actual = dataset.iloc[i].values  # [producto1, producto2]\n",
    "        \n",
    "        # Obtener últimos valores originales para revertir diferenciación\n",
    "        if use_differenced and original_dataset is not None:\n",
    "            # El último valor original antes de la diferenciación\n",
    "            last_original_idx = i + diff_order - 1\n",
    "            if last_original_idx >= 0 and last_original_idx < len(original_dataset):\n",
    "                original_last_values = original_dataset.iloc[last_original_idx].values\n",
    "            else:\n",
    "                original_last_values = original_dataset.iloc[0].values\n",
    "        else:\n",
    "            original_last_values = None\n",
    "        \n",
    "        # Realizar predicción\n",
    "        try:\n",
    "            forecast = var_forecast(\n",
    "                train_data, \n",
    "                order=order, \n",
    "                forecast_horizon=1,\n",
    "                use_differenced=use_differenced,\n",
    "                diff_order=diff_order,\n",
    "                original_last_values=original_last_values\n",
    "            )\n",
    "            prediction = forecast[0]  # Primera (y única) predicción: [producto1, producto2]\n",
    "        except Exception as e:\n",
    "            if use_differenced and original_dataset is not None:\n",
    "                prediction = original_last_values if original_last_values is not None else original_dataset.iloc[0].values\n",
    "            else:\n",
    "                prediction = train_data.iloc[-1].values  # Fallback al último valor\n",
    "        \n",
    "        # Calcular métricas para cada producto\n",
    "        # Producto 1\n",
    "        rmse_p1 = np.sqrt(mean_squared_error([actual[0]], [prediction[0]]))\n",
    "        mae_p1 = mean_absolute_error([actual[0]], [prediction[0]])\n",
    "        \n",
    "        metrics_list_p1.append({\n",
    "            'iteracion': i - train_size_min + 1,\n",
    "            'ventana': i,\n",
    "            'rmse': rmse_p1,\n",
    "            'mae': mae_p1\n",
    "        })\n",
    "        \n",
    "        # Producto 2\n",
    "        rmse_p2 = np.sqrt(mean_squared_error([actual[1]], [prediction[1]]))\n",
    "        mae_p2 = mean_absolute_error([actual[1]], [prediction[1]])\n",
    "        \n",
    "        metrics_list_p2.append({\n",
    "            'iteracion': i - train_size_min + 1,\n",
    "            'ventana': i,\n",
    "            'rmse': rmse_p2,\n",
    "            'mae': mae_p2\n",
    "        })\n",
    "        \n",
    "        if (i - train_size_min + 1) % 20 == 0:\n",
    "            print(f\"  Iteración {i - train_size_min + 1}/{n - train_size_min}: \"\n",
    "                  f\"RMSE_p1={rmse_p1:.4f}, RMSE_p2={rmse_p2:.4f}\")\n",
    "    \n",
    "    results['producto1'] = metrics_list_p1\n",
    "    results['producto2'] = metrics_list_p2\n",
    "    \n",
    "    print(f\"  Total de iteraciones: {len(metrics_list_p1)}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2bf0b9",
   "metadata": {},
   "source": [
    "## Función 2: Rolling Window Validation\n",
    "\n",
    "En Rolling Window Validation, se utiliza una ventana fija de tamaño constante que se desliza a lo largo de la serie temporal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bea3e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_validation(dataset, order, train_window_size=24, use_differenced=True, diff_order=1, original_dataset=None):\n",
    "    \"\"\"\n",
    "    Realiza validación Rolling Window para el modelo VAR multivariado.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : pandas.DataFrame\n",
    "        Dataset con las columnas de productos (producto1 y producto2) - datos diferenciados\n",
    "    order : int\n",
    "        Orden del modelo VAR\n",
    "    train_window_size : int\n",
    "        Tamaño fijo de la ventana de entrenamiento (por defecto 24)\n",
    "    use_differenced : bool\n",
    "        Si True, los datos están diferenciados\n",
    "    diff_order : int\n",
    "        Orden de diferenciación aplicado\n",
    "    original_dataset : pandas.DataFrame, optional\n",
    "        Dataset original antes de diferenciación (necesario para obtener valores reales)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con métricas para cada producto:\n",
    "        - 'producto1': lista de diccionarios con métricas por iteración\n",
    "        - 'producto2': lista de diccionarios con métricas por iteración\n",
    "        Cada diccionario contiene: iteracion, ventana, rmse, mae\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    n = len(dataset)\n",
    "    \n",
    "    # Inicializar listas de métricas para cada producto\n",
    "    metrics_list_p1 = []\n",
    "    metrics_list_p2 = []\n",
    "    \n",
    "    print(f\"\\n=== Rolling Window Validation para Modelo VAR (orden={order}) ===\")\n",
    "    \n",
    "    # Comenzar desde train_window_size hasta n-1\n",
    "    for i in range(train_window_size, n):\n",
    "        # Datos de entrenamiento: ventana fija de tamaño train_window_size\n",
    "        train_data = dataset.iloc[i - train_window_size:i]\n",
    "        # Datos de validación: i (en escala original si usamos diferenciación)\n",
    "        if use_differenced and original_dataset is not None:\n",
    "            actual_idx = i + diff_order\n",
    "            if actual_idx < len(original_dataset):\n",
    "                actual = original_dataset.iloc[actual_idx].values\n",
    "            else:\n",
    "                actual = original_dataset.iloc[-1].values\n",
    "        else:\n",
    "            actual = dataset.iloc[i].values  # [producto1, producto2]\n",
    "        \n",
    "        # Obtener últimos valores originales para revertir diferenciación\n",
    "        if use_differenced and original_dataset is not None:\n",
    "            last_original_idx = i + diff_order - 1\n",
    "            if last_original_idx >= 0 and last_original_idx < len(original_dataset):\n",
    "                original_last_values = original_dataset.iloc[last_original_idx].values\n",
    "            else:\n",
    "                original_last_values = original_dataset.iloc[0].values\n",
    "        else:\n",
    "            original_last_values = None\n",
    "        \n",
    "        # Realizar predicción\n",
    "        try:\n",
    "            forecast = var_forecast(\n",
    "                train_data, \n",
    "                order=order, \n",
    "                forecast_horizon=1,\n",
    "                use_differenced=use_differenced,\n",
    "                diff_order=diff_order,\n",
    "                original_last_values=original_last_values\n",
    "            )\n",
    "            prediction = forecast[0]  # Primera (y única) predicción: [producto1, producto2]\n",
    "        except Exception as e:\n",
    "            if use_differenced and original_dataset is not None:\n",
    "                prediction = original_last_values if original_last_values is not None else original_dataset.iloc[0].values\n",
    "            else:\n",
    "                prediction = train_data.iloc[-1].values  # Fallback al último valor\n",
    "        \n",
    "        # Calcular métricas para cada producto\n",
    "        # Producto 1\n",
    "        rmse_p1 = np.sqrt(mean_squared_error([actual[0]], [prediction[0]]))\n",
    "        mae_p1 = mean_absolute_error([actual[0]], [prediction[0]])\n",
    "        \n",
    "        metrics_list_p1.append({\n",
    "            'iteracion': i - train_window_size + 1,\n",
    "            'ventana': f\"{i - train_window_size}-{i}\",\n",
    "            'rmse': rmse_p1,\n",
    "            'mae': mae_p1\n",
    "        })\n",
    "        \n",
    "        # Producto 2\n",
    "        rmse_p2 = np.sqrt(mean_squared_error([actual[1]], [prediction[1]]))\n",
    "        mae_p2 = mean_absolute_error([actual[1]], [prediction[1]])\n",
    "        \n",
    "        metrics_list_p2.append({\n",
    "            'iteracion': i - train_window_size + 1,\n",
    "            'ventana': f\"{i - train_window_size}-{i}\",\n",
    "            'rmse': rmse_p2,\n",
    "            'mae': mae_p2\n",
    "        })\n",
    "        \n",
    "        if (i - train_window_size + 1) % 20 == 0:\n",
    "            print(f\"  Iteración {i - train_window_size + 1}/{n - train_window_size}: \"\n",
    "                  f\"RMSE_p1={rmse_p1:.4f}, RMSE_p2={rmse_p2:.4f}\")\n",
    "    \n",
    "    results['producto1'] = metrics_list_p1\n",
    "    results['producto2'] = metrics_list_p2\n",
    "    \n",
    "    print(f\"  Total de iteraciones: {len(metrics_list_p1)}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f32212",
   "metadata": {},
   "source": [
    "## Función 3: Expanding Window Validation\n",
    "\n",
    "En Expanding Window Validation, la ventana de entrenamiento crece con cada iteración, comenzando desde un tamaño mínimo y expandiéndose hasta incluir todos los datos disponibles hasta ese punto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2e852ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_window_validation(dataset, order, train_size_min=24, use_differenced=True, diff_order=1, original_dataset=None):\n",
    "    \"\"\"\n",
    "    Realiza validación Expanding Window para el modelo VAR multivariado.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : pandas.DataFrame\n",
    "        Dataset con las columnas de productos (producto1 y producto2) - datos diferenciados\n",
    "    order : int\n",
    "        Orden del modelo VAR\n",
    "    train_size_min : int\n",
    "        Tamaño mínimo inicial de la ventana de entrenamiento (por defecto 24)\n",
    "    use_differenced : bool\n",
    "        Si True, los datos están diferenciados\n",
    "    diff_order : int\n",
    "        Orden de diferenciación aplicado\n",
    "    original_dataset : pandas.DataFrame, optional\n",
    "        Dataset original antes de diferenciación (necesario para obtener valores reales)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con métricas para cada producto:\n",
    "        - 'producto1': lista de diccionarios con métricas por iteración\n",
    "        - 'producto2': lista de diccionarios con métricas por iteración\n",
    "        Cada diccionario contiene: iteracion, ventana, rmse, mae\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    n = len(dataset)\n",
    "    \n",
    "    # Inicializar listas de métricas para cada producto\n",
    "    metrics_list_p1 = []\n",
    "    metrics_list_p2 = []\n",
    "    \n",
    "    print(f\"\\n=== Expanding Window Validation para Modelo VAR (orden={order}) ===\")\n",
    "    \n",
    "    # Comenzar validación desde train_size_min hasta n-1\n",
    "    for i in range(train_size_min, n):\n",
    "        # Datos de entrenamiento: desde el inicio hasta i (ventana que se expande)\n",
    "        train_data = dataset.iloc[:i]\n",
    "        # Datos de validación: i (en escala original si usamos diferenciación)\n",
    "        if use_differenced and original_dataset is not None:\n",
    "            actual_idx = i + diff_order\n",
    "            if actual_idx < len(original_dataset):\n",
    "                actual = original_dataset.iloc[actual_idx].values\n",
    "            else:\n",
    "                actual = original_dataset.iloc[-1].values\n",
    "        else:\n",
    "            actual = dataset.iloc[i].values  # [producto1, producto2]\n",
    "        \n",
    "        # Obtener últimos valores originales para revertir diferenciación\n",
    "        if use_differenced and original_dataset is not None:\n",
    "            last_original_idx = i + diff_order - 1\n",
    "            if last_original_idx >= 0 and last_original_idx < len(original_dataset):\n",
    "                original_last_values = original_dataset.iloc[last_original_idx].values\n",
    "            else:\n",
    "                original_last_values = original_dataset.iloc[0].values\n",
    "        else:\n",
    "            original_last_values = None\n",
    "        \n",
    "        # Realizar predicción\n",
    "        try:\n",
    "            forecast = var_forecast(\n",
    "                train_data, \n",
    "                order=order, \n",
    "                forecast_horizon=1,\n",
    "                use_differenced=use_differenced,\n",
    "                diff_order=diff_order,\n",
    "                original_last_values=original_last_values\n",
    "            )\n",
    "            prediction = forecast[0]  # Primera (y única) predicción: [producto1, producto2]\n",
    "        except Exception as e:\n",
    "            if use_differenced and original_dataset is not None:\n",
    "                prediction = original_last_values if original_last_values is not None else original_dataset.iloc[0].values\n",
    "            else:\n",
    "                prediction = train_data.iloc[-1].values  # Fallback al último valor\n",
    "        \n",
    "        # Calcular métricas para cada producto\n",
    "        # Producto 1\n",
    "        rmse_p1 = np.sqrt(mean_squared_error([actual[0]], [prediction[0]]))\n",
    "        mae_p1 = mean_absolute_error([actual[0]], [prediction[0]])\n",
    "        \n",
    "        metrics_list_p1.append({\n",
    "            'iteracion': i - train_size_min + 1,\n",
    "            'ventana': i,  # Tamaño de la ventana que se expande\n",
    "            'rmse': rmse_p1,\n",
    "            'mae': mae_p1\n",
    "        })\n",
    "        \n",
    "        # Producto 2\n",
    "        rmse_p2 = np.sqrt(mean_squared_error([actual[1]], [prediction[1]]))\n",
    "        mae_p2 = mean_absolute_error([actual[1]], [prediction[1]])\n",
    "        \n",
    "        metrics_list_p2.append({\n",
    "            'iteracion': i - train_size_min + 1,\n",
    "            'ventana': i,  # Tamaño de la ventana que se expande\n",
    "            'rmse': rmse_p2,\n",
    "            'mae': mae_p2\n",
    "        })\n",
    "        \n",
    "        if (i - train_size_min + 1) % 20 == 0:\n",
    "            print(f\"  Iteración {i - train_size_min + 1}/{n - train_size_min}: \"\n",
    "                  f\"RMSE_p1={rmse_p1:.4f}, RMSE_p2={rmse_p2:.4f}\")\n",
    "    \n",
    "    results['producto1'] = metrics_list_p1\n",
    "    results['producto2'] = metrics_list_p2\n",
    "    \n",
    "    print(f\"  Total de iteraciones: {len(metrics_list_p1)}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b24b52",
   "metadata": {},
   "source": [
    "## Ejecución de las Validaciones\n",
    "\n",
    "Después de definir las funciones que permitirán ejecutar el modelo teniendo en cuenta los tres tipos de validación, ahora ejecutamos las tres validaciones usando los **datos diferenciados** (si se aplicó diferenciación) y calculamos las métricas promedio.\n",
    "\n",
    "**Configuración inicial del modelo VAR:**\n",
    "- Orden inicial: 2 (se optimizará después)\n",
    "- Datos: Se usarán los datos diferenciados si están disponibles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13db0a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURACIÓN INICIAL DEL MODELO VAR\n",
      "============================================================\n",
      "Tamaño mínimo de entrenamiento: 24\n",
      "Tamaño de ventana fija (Rolling): 24\n",
      "Orden inicial del modelo VAR: 2\n",
      "\n",
      "✓ Se usarán datos diferenciados (orden: 2)\n",
      "  Datos originales: 127 observaciones\n",
      "  Datos diferenciados: 125 observaciones\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de validación\n",
    "TRAIN_SIZE_MIN = 24  # Tamaño mínimo de entrenamiento\n",
    "TRAIN_WINDOW_SIZE = 24  # Tamaño fijo para Rolling Window\n",
    "\n",
    "# Orden inicial del modelo VAR (se optimizará después)\n",
    "INITIAL_ORDER = 2\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURACIÓN INICIAL DEL MODELO VAR\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Tamaño mínimo de entrenamiento: {TRAIN_SIZE_MIN}\")\n",
    "print(f\"Tamaño de ventana fija (Rolling): {TRAIN_WINDOW_SIZE}\")\n",
    "print(f\"Orden inicial del modelo VAR: {INITIAL_ORDER}\")\n",
    "\n",
    "# Verificar si se aplicó diferenciación y usar datos diferenciados\n",
    "if 'USE_DIFFERENCED_DATA' in globals() and USE_DIFFERENCED_DATA:\n",
    "    print(f\"\\n✓ Se usarán datos diferenciados (orden: {DIFF_ORDER})\")\n",
    "    print(f\"  Datos originales: {len(df_original)} observaciones\")\n",
    "    print(f\"  Datos diferenciados: {len(df_diff)} observaciones\")\n",
    "    data_for_validation = df_diff\n",
    "else:\n",
    "    print(f\"\\n✓ Se usarán datos originales (sin diferenciación)\")\n",
    "    data_for_validation = df\n",
    "    USE_DIFFERENCED_DATA = False\n",
    "    DIFF_ORDER = 0\n",
    "    df_original = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d68da82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WALK-FORWARD VALIDATION\n",
      "============================================================\n",
      "\n",
      "=== Walk-Forward Validation para Modelo VAR (orden=2) ===\n",
      "  Iteración 20/101: RMSE_p1=12.1990, RMSE_p2=30.4574\n",
      "  Iteración 40/101: RMSE_p1=18.1531, RMSE_p2=5.0658\n",
      "  Iteración 60/101: RMSE_p1=8.0479, RMSE_p2=14.3486\n",
      "  Iteración 80/101: RMSE_p1=14.0772, RMSE_p2=7.0468\n",
      "  Iteración 100/101: RMSE_p1=1.2306, RMSE_p2=25.4724\n",
      "  Total de iteraciones: 101\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar Walk-Forward Validation usando datos diferenciados\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WALK-FORWARD VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_wf = walk_forward_validation(\n",
    "    data_for_validation,\n",
    "    order=INITIAL_ORDER,\n",
    "    train_size_min=TRAIN_SIZE_MIN,\n",
    "    use_differenced=USE_DIFFERENCED_DATA,\n",
    "    diff_order=DIFF_ORDER,\n",
    "    original_dataset=df_original if USE_DIFFERENCED_DATA else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76f7db57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ROLLING WINDOW VALIDATION\n",
      "============================================================\n",
      "\n",
      "=== Rolling Window Validation para Modelo VAR (orden=2) ===\n",
      "  Iteración 20/101: RMSE_p1=10.4176, RMSE_p2=29.8716\n",
      "  Iteración 40/101: RMSE_p1=17.9838, RMSE_p2=12.4813\n",
      "  Iteración 60/101: RMSE_p1=4.6937, RMSE_p2=14.0650\n",
      "  Iteración 80/101: RMSE_p1=11.8929, RMSE_p2=7.8938\n",
      "  Iteración 100/101: RMSE_p1=2.1791, RMSE_p2=22.0828\n",
      "  Total de iteraciones: 101\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar Rolling Window Validation usando datos diferenciados\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ROLLING WINDOW VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_rw = rolling_window_validation(\n",
    "    data_for_validation,\n",
    "    order=INITIAL_ORDER,\n",
    "    train_window_size=TRAIN_WINDOW_SIZE,\n",
    "    use_differenced=USE_DIFFERENCED_DATA,\n",
    "    diff_order=DIFF_ORDER,\n",
    "    original_dataset=df_original if USE_DIFFERENCED_DATA else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "868314e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPANDING WINDOW VALIDATION\n",
      "============================================================\n",
      "\n",
      "=== Expanding Window Validation para Modelo VAR (orden=2) ===\n",
      "  Iteración 20/101: RMSE_p1=12.1990, RMSE_p2=30.4574\n",
      "  Iteración 40/101: RMSE_p1=18.1531, RMSE_p2=5.0658\n",
      "  Iteración 60/101: RMSE_p1=8.0479, RMSE_p2=14.3486\n",
      "  Iteración 80/101: RMSE_p1=14.0772, RMSE_p2=7.0468\n",
      "  Iteración 100/101: RMSE_p1=1.2306, RMSE_p2=25.4724\n",
      "  Total de iteraciones: 101\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar Expanding Window Validation usando datos diferenciados\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPANDING WINDOW VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_ew = expanding_window_validation(\n",
    "    data_for_validation,\n",
    "    order=INITIAL_ORDER,\n",
    "    train_size_min=TRAIN_SIZE_MIN,\n",
    "    use_differenced=USE_DIFFERENCED_DATA,\n",
    "    diff_order=DIFF_ORDER,\n",
    "    original_dataset=df_original if USE_DIFFERENCED_DATA else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "107bf93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MÉTRICAS PROMEDIO - WALK-FORWARD\n",
      "============================================================\n",
      "\n",
      "producto1:\n",
      "  RMSE Promedio: 8.9271\n",
      "  MAE Promedio: 8.9271\n",
      "  Número de iteraciones: 101\n",
      "\n",
      "producto2:\n",
      "  RMSE Promedio: 15.1489\n",
      "  MAE Promedio: 15.1489\n",
      "  Número de iteraciones: 101\n",
      "\n",
      "============================================================\n",
      "MÉTRICAS PROMEDIO - ROLLING WINDOW\n",
      "============================================================\n",
      "\n",
      "producto1:\n",
      "  RMSE Promedio: 9.2028\n",
      "  MAE Promedio: 9.2028\n",
      "  Número de iteraciones: 101\n",
      "\n",
      "producto2:\n",
      "  RMSE Promedio: 15.5392\n",
      "  MAE Promedio: 15.5392\n",
      "  Número de iteraciones: 101\n",
      "\n",
      "============================================================\n",
      "MÉTRICAS PROMEDIO - EXPANDING WINDOW\n",
      "============================================================\n",
      "\n",
      "producto1:\n",
      "  RMSE Promedio: 8.9271\n",
      "  MAE Promedio: 8.9271\n",
      "  Número de iteraciones: 101\n",
      "\n",
      "producto2:\n",
      "  RMSE Promedio: 15.1489\n",
      "  MAE Promedio: 15.1489\n",
      "  Número de iteraciones: 101\n"
     ]
    }
   ],
   "source": [
    "def calcular_metricas_promedio(results, nombre_validacion):\n",
    "    \"\"\"\n",
    "    Calcula las métricas promedio para cada producto.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Resultados de la validación\n",
    "    nombre_validacion : str\n",
    "        Nombre del tipo de validación\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con métricas promedio por producto\n",
    "    \"\"\"\n",
    "    metricas_promedio = {}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MÉTRICAS PROMEDIO - {nombre_validacion.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for producto in results.keys():\n",
    "        metrics_list = results[producto]\n",
    "        \n",
    "        # Calcular promedios\n",
    "        rmse_promedio = np.mean([m['rmse'] for m in metrics_list])\n",
    "        mae_promedio = np.mean([m['mae'] for m in metrics_list])\n",
    "        \n",
    "        metricas_promedio[producto] = {\n",
    "            'rmse_promedio': rmse_promedio,\n",
    "            'mae_promedio': mae_promedio,\n",
    "            'num_iteraciones': len(metrics_list)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{producto}:\")\n",
    "        print(f\"  RMSE Promedio: {rmse_promedio:.4f}\")\n",
    "        print(f\"  MAE Promedio: {mae_promedio:.4f}\")\n",
    "        print(f\"  Número de iteraciones: {len(metrics_list)}\")\n",
    "    \n",
    "    return metricas_promedio\n",
    "\n",
    "# Calcular métricas promedio para cada tipo de validación\n",
    "metricas_wf = calcular_metricas_promedio(results_wf, \"Walk-Forward\")\n",
    "metricas_rw = calcular_metricas_promedio(results_rw, \"Rolling Window\")\n",
    "metricas_ew = calcular_metricas_promedio(results_ew, \"Expanding Window\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0491b9d",
   "metadata": {},
   "source": [
    "## Comparación de Resultados y Selección del Mejor Método de Validación\n",
    "\n",
    "Comparamos los RMSE promedio de cada tipo de validación para seleccionar el mejor método. Para modelos multivariados, consideramos el RMSE promedio de ambas series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2d2c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARACIÓN DE MÉTODOS DE VALIDACIÓN\n",
      "================================================================================\n",
      " Producto       Validacion  RMSE_Promedio  MAE_Promedio\n",
      "producto1     Walk-Forward       8.927137      8.927137\n",
      "producto1   Rolling Window       9.202775      9.202775\n",
      "producto1 Expanding Window       8.927137      8.927137\n",
      "producto2     Walk-Forward      15.148872     15.148872\n",
      "producto2   Rolling Window      15.539231     15.539231\n",
      "producto2 Expanding Window      15.148872     15.148872\n",
      "\n",
      "================================================================================\n",
      "RMSE PROMEDIO AGREGADO (promedio de ambos productos)\n",
      "================================================================================\n",
      "Walk-Forward: 12.0380\n",
      "Rolling Window: 12.3710\n",
      "Expanding Window: 12.0380\n",
      "\n",
      "Mejor método de validación (basado en RMSE agregado): Walk-Forward\n",
      "\n",
      "================================================================================\n",
      "MEJOR MÉTODO DE VALIDACIÓN POR PRODUCTO (basado en RMSE Promedio)\n",
      "================================================================================\n",
      "\n",
      "producto1:\n",
      "  Mejor método: Walk-Forward\n",
      "  RMSE Promedio: 8.9271\n",
      "\n",
      "producto2:\n",
      "  Mejor método: Walk-Forward\n",
      "  RMSE Promedio: 15.1489\n",
      "\n",
      "================================================================================\n",
      "MÉTODO SELECCIONADO PARA OPTIMIZACIÓN: Walk-Forward\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Crear DataFrame comparativo\n",
    "comparacion = []\n",
    "\n",
    "for producto in df.columns:\n",
    "    comparacion.append({\n",
    "        'Producto': producto,\n",
    "        'Validacion': 'Walk-Forward',\n",
    "        'RMSE_Promedio': metricas_wf[producto]['rmse_promedio'],\n",
    "        'MAE_Promedio': metricas_wf[producto]['mae_promedio']\n",
    "    })\n",
    "    comparacion.append({\n",
    "        'Producto': producto,\n",
    "        'Validacion': 'Rolling Window',\n",
    "        'RMSE_Promedio': metricas_rw[producto]['rmse_promedio'],\n",
    "        'MAE_Promedio': metricas_rw[producto]['mae_promedio']\n",
    "    })\n",
    "    comparacion.append({\n",
    "        'Producto': producto,\n",
    "        'Validacion': 'Expanding Window',\n",
    "        'RMSE_Promedio': metricas_ew[producto]['rmse_promedio'],\n",
    "        'MAE_Promedio': metricas_ew[producto]['mae_promedio']\n",
    "    })\n",
    "\n",
    "df_comparacion = pd.DataFrame(comparacion)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARACIÓN DE MÉTODOS DE VALIDACIÓN\")\n",
    "print(\"=\" * 80)\n",
    "print(df_comparacion.to_string(index=False))\n",
    "\n",
    "# Calcular RMSE promedio agregado (promedio de ambos productos) para cada método\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RMSE PROMEDIO AGREGADO (promedio de ambos productos)\")\n",
    "print(\"=\" * 80)\n",
    "rmse_agregado = {}\n",
    "for validacion in ['Walk-Forward', 'Rolling Window', 'Expanding Window']:\n",
    "    rmse_p1 = df_comparacion[(df_comparacion['Validacion'] == validacion) & \n",
    "                             (df_comparacion['Producto'] == 'producto1')]['RMSE_Promedio'].values[0]\n",
    "    rmse_p2 = df_comparacion[(df_comparacion['Validacion'] == validacion) & \n",
    "                             (df_comparacion['Producto'] == 'producto2')]['RMSE_Promedio'].values[0]\n",
    "    rmse_agregado[validacion] = (rmse_p1 + rmse_p2) / 2\n",
    "    print(f\"{validacion}: {rmse_agregado[validacion]:.4f}\")\n",
    "\n",
    "# Identificar el mejor método basado en RMSE agregado\n",
    "mejor_validacion_agregada = min(rmse_agregado, key=rmse_agregado.get)\n",
    "print(f\"\\nMejor método de validación (basado en RMSE agregado): {mejor_validacion_agregada}\")\n",
    "\n",
    "# Identificar el mejor método para cada producto\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MEJOR MÉTODO DE VALIDACIÓN POR PRODUCTO (basado en RMSE Promedio)\")\n",
    "print(\"=\" * 80)\n",
    "mejor_validacion = {}\n",
    "for producto in df.columns:\n",
    "    producto_df = df_comparacion[df_comparacion['Producto'] == producto]\n",
    "    mejor = producto_df.loc[producto_df['RMSE_Promedio'].idxmin()]\n",
    "    mejor_validacion[producto] = mejor['Validacion']\n",
    "    print(f\"\\n{producto}:\")\n",
    "    print(f\"  Mejor método: {mejor['Validacion']}\")\n",
    "    print(f\"  RMSE Promedio: {mejor['RMSE_Promedio']:.4f}\")\n",
    "\n",
    "# Usar el mejor método agregado para optimización\n",
    "mejor_metodo_global = mejor_validacion_agregada\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"MÉTODO SELECCIONADO PARA OPTIMIZACIÓN: {mejor_metodo_global}\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ef5ba",
   "metadata": {},
   "source": [
    "## Optimización Bayesiana para Encontrar el Mejor Orden del Modelo VAR\n",
    "\n",
    "Utilizamos Optimización Bayesiana (Optuna) para optimizar el orden del modelo VAR. El orden determina cuántos lags de ambas series se incluyen en el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e33d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_walk_forward(trial, data, train_size_min=24, use_differenced=True, diff_order=1, original_dataset=None):\n",
    "    \"\"\"\n",
    "    Función objetivo para optimización bayesiana usando Walk-Forward Validation.\n",
    "    \"\"\"\n",
    "    order = trial.suggest_int('order', 1, 10)\n",
    "    \n",
    "    n = len(data)\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(train_size_min, n):\n",
    "        train_data = data.iloc[:i]\n",
    "        \n",
    "        # Obtener valor real en escala original\n",
    "        if use_differenced and original_dataset is not None:\n",
    "            actual_idx = i + diff_order\n",
    "            if actual_idx < len(original_dataset):\n",
    "                actual = original_dataset.iloc[actual_idx].values\n",
    "            else:\n",
    "                actual = original_dataset.iloc[-1].values\n",
    "            last_original_idx = i + diff_order - 1\n",
    "            if last_original_idx >= 0 and last_original_idx < len(original_dataset):\n",
    "                original_last_values = original_dataset.iloc[last_original_idx].values\n",
    "            else:\n",
    "                original_last_values = original_dataset.iloc[0].values\n",
    "        else:\n",
    "            actual = data.iloc[i].values\n",
    "            original_last_values = None\n",
    "        \n",
    "        try:\n",
    "            forecast = var_forecast(\n",
    "                train_data, \n",
    "                order=order, \n",
    "                forecast_horizon=1,\n",
    "                use_differenced=use_differenced,\n",
    "                diff_order=diff_order,\n",
    "                original_last_values=original_last_values\n",
    "            )\n",
    "            prediction = forecast[0]\n",
    "            \n",
    "            # Calcular RMSE agregado (promedio de ambos productos)\n",
    "            rmse_p1 = np.sqrt(mean_squared_error([actual[0]], [prediction[0]]))\n",
    "            rmse_p2 = np.sqrt(mean_squared_error([actual[1]], [prediction[1]]))\n",
    "            rmse_agregado = (rmse_p1 + rmse_p2) / 2\n",
    "            \n",
    "            if np.isfinite(rmse_agregado):\n",
    "                errors.append(rmse_agregado)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(errors) == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    return np.mean(errors)\n",
    "\n",
    "def objective_rolling_window(trial, data, train_window_size=24, use_differenced=True, diff_order=1, original_dataset=None):\n",
    "    \"\"\"\n",
    "    Función objetivo para optimización bayesiana usando Rolling Window Validation.\n",
    "    \"\"\"\n",
    "    order = trial.suggest_int('order', 1, 10)\n",
    "    \n",
    "    n = len(data)\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(train_window_size, n):\n",
    "        train_data = data.iloc[i - train_window_size:i]\n",
    "        \n",
    "        # Obtener valor real en escala original\n",
    "        if use_differenced and original_dataset is not None:\n",
    "            actual_idx = i + diff_order\n",
    "            if actual_idx < len(original_dataset):\n",
    "                actual = original_dataset.iloc[actual_idx].values\n",
    "            else:\n",
    "                actual = original_dataset.iloc[-1].values\n",
    "            last_original_idx = i + diff_order - 1\n",
    "            if last_original_idx >= 0 and last_original_idx < len(original_dataset):\n",
    "                original_last_values = original_dataset.iloc[last_original_idx].values\n",
    "            else:\n",
    "                original_last_values = original_dataset.iloc[0].values\n",
    "        else:\n",
    "            actual = data.iloc[i].values\n",
    "            original_last_values = None\n",
    "        \n",
    "        try:\n",
    "            forecast = var_forecast(\n",
    "                train_data, \n",
    "                order=order, \n",
    "                forecast_horizon=1,\n",
    "                use_differenced=use_differenced,\n",
    "                diff_order=diff_order,\n",
    "                original_last_values=original_last_values\n",
    "            )\n",
    "            prediction = forecast[0]\n",
    "            \n",
    "            # Calcular RMSE agregado (promedio de ambos productos)\n",
    "            rmse_p1 = np.sqrt(mean_squared_error([actual[0]], [prediction[0]]))\n",
    "            rmse_p2 = np.sqrt(mean_squared_error([actual[1]], [prediction[1]]))\n",
    "            rmse_agregado = (rmse_p1 + rmse_p2) / 2\n",
    "            \n",
    "            if np.isfinite(rmse_agregado):\n",
    "                errors.append(rmse_agregado)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(errors) == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    return np.mean(errors)\n",
    "\n",
    "def objective_expanding_window(trial, data, train_size_min=24, use_differenced=True, diff_order=1, original_dataset=None):\n",
    "    \"\"\"\n",
    "    Función objetivo para optimización bayesiana usando Expanding Window Validation.\n",
    "    \"\"\"\n",
    "    order = trial.suggest_int('order', 1, 10)\n",
    "    \n",
    "    n = len(data)\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(train_size_min, n):\n",
    "        train_data = data.iloc[:i]\n",
    "        \n",
    "        # Obtener valor real en escala original\n",
    "        if use_differenced and original_dataset is not None:\n",
    "            actual_idx = i + diff_order\n",
    "            if actual_idx < len(original_dataset):\n",
    "                actual = original_dataset.iloc[actual_idx].values\n",
    "            else:\n",
    "                actual = original_dataset.iloc[-1].values\n",
    "            last_original_idx = i + diff_order - 1\n",
    "            if last_original_idx >= 0 and last_original_idx < len(original_dataset):\n",
    "                original_last_values = original_dataset.iloc[last_original_idx].values\n",
    "            else:\n",
    "                original_last_values = original_dataset.iloc[0].values\n",
    "        else:\n",
    "            actual = data.iloc[i].values\n",
    "            original_last_values = None\n",
    "        \n",
    "        try:\n",
    "            forecast = var_forecast(\n",
    "                train_data, \n",
    "                order=order, \n",
    "                forecast_horizon=1,\n",
    "                use_differenced=use_differenced,\n",
    "                diff_order=diff_order,\n",
    "                original_last_values=original_last_values\n",
    "            )\n",
    "            prediction = forecast[0]\n",
    "            \n",
    "            # Calcular RMSE agregado (promedio de ambos productos)\n",
    "            rmse_p1 = np.sqrt(mean_squared_error([actual[0]], [prediction[0]]))\n",
    "            rmse_p2 = np.sqrt(mean_squared_error([actual[1]], [prediction[1]]))\n",
    "            rmse_agregado = (rmse_p1 + rmse_p2) / 2\n",
    "            \n",
    "            if np.isfinite(rmse_agregado):\n",
    "                errors.append(rmse_agregado)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(errors) == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    return np.mean(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccf80271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 18:40:08,392] A new study created in memory with name: no-name-97593c74-0109-4196-8edc-c5a432ab61aa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMIZACIÓN BAYESIANA\n",
      "================================================================================\n",
      "Método de validación seleccionado: Walk-Forward\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f42d7054ea4123803cf020deef088e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 18:40:09,240] Trial 0 finished with value: 12.76430477972954 and parameters: {'order': 7}. Best is trial 0 with value: 12.76430477972954.\n",
      "[I 2025-12-01 18:40:09,932] Trial 1 finished with value: 12.339232234200871 and parameters: {'order': 5}. Best is trial 1 with value: 12.339232234200871.\n",
      "[I 2025-12-01 18:40:10,410] Trial 2 finished with value: 12.075082416761964 and parameters: {'order': 1}. Best is trial 2 with value: 12.075082416761964.\n",
      "[I 2025-12-01 18:40:11,075] Trial 3 finished with value: 12.339232234200871 and parameters: {'order': 5}. Best is trial 2 with value: 12.075082416761964.\n",
      "[I 2025-12-01 18:40:11,672] Trial 4 finished with value: 12.11522046599439 and parameters: {'order': 4}. Best is trial 2 with value: 12.075082416761964.\n",
      "[I 2025-12-01 18:40:12,140] Trial 5 finished with value: 12.038004794558734 and parameters: {'order': 2}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:13,011] Trial 6 finished with value: 14.412549206919353 and parameters: {'order': 10}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:13,531] Trial 7 finished with value: 12.172757820833333 and parameters: {'order': 3}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:14,404] Trial 8 finished with value: 14.412549206919353 and parameters: {'order': 10}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:15,107] Trial 9 finished with value: 12.261184888944705 and parameters: {'order': 6}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:15,532] Trial 10 finished with value: 12.075082416761964 and parameters: {'order': 1}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:15,945] Trial 11 finished with value: 12.075082416761964 and parameters: {'order': 1}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:16,417] Trial 12 finished with value: 12.038004794558734 and parameters: {'order': 2}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:16,945] Trial 13 finished with value: 12.172757820833333 and parameters: {'order': 3}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:17,617] Trial 14 finished with value: 12.172757820833333 and parameters: {'order': 3}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:18,614] Trial 15 finished with value: 12.706978826125644 and parameters: {'order': 8}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:19,298] Trial 16 finished with value: 12.172757820833333 and parameters: {'order': 3}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:19,699] Trial 17 finished with value: 12.038004794558734 and parameters: {'order': 2}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:20,085] Trial 18 finished with value: 12.038004794558734 and parameters: {'order': 2}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:20,549] Trial 19 finished with value: 12.11522046599439 and parameters: {'order': 4}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:20,933] Trial 20 finished with value: 12.038004794558734 and parameters: {'order': 2}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:21,323] Trial 21 finished with value: 12.038004794558734 and parameters: {'order': 2}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:21,795] Trial 22 finished with value: 12.11522046599439 and parameters: {'order': 4}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:22,180] Trial 23 finished with value: 12.038004794558734 and parameters: {'order': 2}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:22,517] Trial 24 finished with value: 12.075082416761964 and parameters: {'order': 1}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:22,897] Trial 25 finished with value: 12.038004794558734 and parameters: {'order': 2}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:23,383] Trial 26 finished with value: 12.11522046599439 and parameters: {'order': 4}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:23,943] Trial 27 finished with value: 12.261184888944705 and parameters: {'order': 6}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:24,372] Trial 28 finished with value: 12.172757820833333 and parameters: {'order': 3}. Best is trial 5 with value: 12.038004794558734.\n",
      "[I 2025-12-01 18:40:24,734] Trial 29 finished with value: 12.075082416761964 and parameters: {'order': 1}. Best is trial 5 with value: 12.038004794558734.\n",
      "\n",
      "Mejores parámetros encontrados:\n",
      "  Orden del modelo VAR: 2\n",
      "  RMSE agregado: 12.0380\n",
      "  Método usado: Walk-Forward\n"
     ]
    }
   ],
   "source": [
    "# Realizar optimización bayesiana usando el mejor método de validación\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMIZACIÓN BAYESIANA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Método de validación seleccionado: {mejor_metodo_global}\")\n",
    "\n",
    "# Usar datos diferenciados si están disponibles\n",
    "data_for_optimization = df_diff if USE_DIFFERENCED_DATA else df\n",
    "\n",
    "# Seleccionar función objetivo según el mejor método\n",
    "if mejor_metodo_global == 'Walk-Forward':\n",
    "    objective_func = lambda trial: objective_walk_forward(\n",
    "        trial, data_for_optimization, TRAIN_SIZE_MIN,\n",
    "        use_differenced=USE_DIFFERENCED_DATA,\n",
    "        diff_order=DIFF_ORDER,\n",
    "        original_dataset=df_original if USE_DIFFERENCED_DATA else None\n",
    "    )\n",
    "elif mejor_metodo_global == 'Rolling Window':\n",
    "    objective_func = lambda trial: objective_rolling_window(\n",
    "        trial, data_for_optimization, TRAIN_WINDOW_SIZE,\n",
    "        use_differenced=USE_DIFFERENCED_DATA,\n",
    "        diff_order=DIFF_ORDER,\n",
    "        original_dataset=df_original if USE_DIFFERENCED_DATA else None\n",
    "    )\n",
    "else:  # Expanding Window\n",
    "    objective_func = lambda trial: objective_expanding_window(\n",
    "        trial, data_for_optimization, TRAIN_SIZE_MIN,\n",
    "        use_differenced=USE_DIFFERENCED_DATA,\n",
    "        diff_order=DIFF_ORDER,\n",
    "        original_dataset=df_original if USE_DIFFERENCED_DATA else None\n",
    "    )\n",
    "\n",
    "# Crear estudio de Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_func, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "# Obtener mejores parámetros\n",
    "best_params = study.best_params\n",
    "best_order = best_params['order']\n",
    "best_rmse = study.best_value\n",
    "\n",
    "print(f\"\\nMejores parámetros encontrados:\")\n",
    "print(f\"  Orden del modelo VAR: {best_order}\")\n",
    "print(f\"  RMSE agregado: {best_rmse:.4f}\")\n",
    "print(f\"  Método usado: {mejor_metodo_global}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ef30d",
   "metadata": {},
   "source": [
    "## Análisis de Interdependencias del Modelo VAR\n",
    "\n",
    "Una vez optimizado el modelo, analizamos las interdependencias entre las series para entender cómo se influyen mutuamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13c7b90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANÁLISIS DE INTERDEPENDENCIAS\n",
      "============================================================\n",
      "\n",
      "Modelo VAR entrenado con orden: 2\n",
      "\n",
      "Resumen del modelo:\n",
      "  Summary of Regression Results   \n",
      "==================================\n",
      "Model:                         VAR\n",
      "Method:                        OLS\n",
      "Date:           Mon, 01, Dec, 2025\n",
      "Time:                     18:40:24\n",
      "--------------------------------------------------------------------\n",
      "No. of Equations:         2.00000    BIC:                    8.91010\n",
      "Nobs:                     123.000    HQIC:                   8.77434\n",
      "Log likelihood:          -872.969    FPE:                    5893.22\n",
      "AIC:                      8.68147    Det(Omega_mle):         5441.80\n",
      "--------------------------------------------------------------------\n",
      "Results for equation producto1\n",
      "===============================================================================\n",
      "                  coefficient       std. error           t-stat            prob\n",
      "-------------------------------------------------------------------------------\n",
      "const                0.043242         0.660464            0.065           0.948\n",
      "L1.producto1        -1.107351         0.083593          -13.247           0.000\n",
      "L1.producto2        -0.191385         0.066748           -2.867           0.004\n",
      "L2.producto1        -0.348337         0.083121           -4.191           0.000\n",
      "L2.producto2        -0.181445         0.066769           -2.717           0.007\n",
      "===============================================================================\n",
      "\n",
      "Results for equation producto2\n",
      "===============================================================================\n",
      "                  coefficient       std. error           t-stat            prob\n",
      "-------------------------------------------------------------------------------\n",
      "const               -0.006713         0.918881           -0.007           0.994\n",
      "L1.producto1         0.088033         0.116300            0.757           0.449\n",
      "L1.producto2        -0.941563         0.092864          -10.139           0.000\n",
      "L2.producto1        -0.051450         0.115643           -0.445           0.656\n",
      "L2.producto2        -0.028433         0.092894           -0.306           0.760\n",
      "===============================================================================\n",
      "\n",
      "Correlation matrix of residuals\n",
      "             producto1  producto2\n",
      "producto1     1.000000  -0.151811\n",
      "producto2    -0.151811   1.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "COEFICIENTES DEL MODELO VAR\n",
      "============================================================\n",
      "\n",
      "Ecuación para producto1:\n",
      "  producto1(t) = -1.1074*producto1(t-1) + -0.1914*producto2(t-1) + -0.3483*producto1(t-2) + -0.1814*producto2(t-2)\n",
      "\n",
      "Ecuación para producto2:\n",
      "  producto2(t) = 0.0880*producto1(t-1) + -0.9416*producto2(t-1) + -0.0515*producto1(t-2) + -0.0284*producto2(t-2)\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelo VAR con el mejor orden para análisis\n",
    "print(\"=\" * 60)\n",
    "print(\"ANÁLISIS DE INTERDEPENDENCIAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Usar datos diferenciados si están disponibles\n",
    "data_for_analysis = df_diff if USE_DIFFERENCED_DATA else df\n",
    "\n",
    "model_var = VAR(data_for_analysis)\n",
    "fit_var = model_var.fit(maxlags=best_order, ic='aic')\n",
    "\n",
    "print(f\"\\nModelo VAR entrenado con orden: {best_order}\")\n",
    "print(f\"\\nResumen del modelo:\")\n",
    "print(fit_var.summary())\n",
    "\n",
    "# Obtener coeficientes del modelo\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"COEFICIENTES DEL MODELO VAR\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nEcuación para producto1:\")\n",
    "print(\"  producto1(t) = \", end=\"\")\n",
    "for lag in range(1, best_order + 1):\n",
    "    coef_p1_p1 = fit_var.coefs[lag-1][0, 0]\n",
    "    coef_p1_p2 = fit_var.coefs[lag-1][0, 1]\n",
    "    print(f\"{coef_p1_p1:.4f}*producto1(t-{lag}) + {coef_p1_p2:.4f}*producto2(t-{lag})\", end=\"\")\n",
    "    if lag < best_order:\n",
    "        print(\" + \", end=\"\")\n",
    "print()\n",
    "\n",
    "print(\"\\nEcuación para producto2:\")\n",
    "print(\"  producto2(t) = \", end=\"\")\n",
    "for lag in range(1, best_order + 1):\n",
    "    coef_p2_p1 = fit_var.coefs[lag-1][1, 0]\n",
    "    coef_p2_p2 = fit_var.coefs[lag-1][1, 1]\n",
    "    print(f\"{coef_p2_p1:.4f}*producto1(t-{lag}) + {coef_p2_p2:.4f}*producto2(t-{lag})\", end=\"\")\n",
    "    if lag < best_order:\n",
    "        print(\" + \", end=\"\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146732a8",
   "metadata": {},
   "source": [
    "## Modelo Final para Producción\n",
    "\n",
    "Entrenamos el modelo final con todos los datos disponibles usando el mejor orden encontrado mediante optimización bayesiana y realizamos la predicción para el siguiente mes (1 pronóstico para ambas series).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "561a63e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PREDICCIÓN FINAL PARA PRODUCCIÓN\n",
      "================================================================================\n",
      "Parámetros del modelo:\n",
      "  Orden del modelo VAR: 2\n",
      "  RMSE en validación: 12.0380\n",
      "  Método de validación usado: Walk-Forward\n",
      "  Diferenciación aplicada: orden 2\n",
      "\n",
      "Predicciones para el siguiente mes:\n",
      "  producto1: 128.1178\n",
      "  producto2: 693.4125\n",
      "\n",
      "Últimos valores observados:\n",
      "  producto1: 141.9909\n",
      "  producto2: 676.0581\n",
      "\n",
      "Diferencias:\n",
      "  producto1: -13.8731\n",
      "  producto2: 17.3544\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DE PREDICCIONES PARA PRODUCCIÓN\n",
      "================================================================================\n",
      "producto1: 128.1178\n",
      "producto2: 693.4125\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelo final y realizar predicción para producción\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREDICCIÓN FINAL PARA PRODUCCIÓN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Parámetros del modelo:\")\n",
    "print(f\"  Orden del modelo VAR: {best_order}\")\n",
    "print(f\"  RMSE en validación: {best_rmse:.4f}\")\n",
    "print(f\"  Método de validación usado: {mejor_metodo_global}\")\n",
    "if USE_DIFFERENCED_DATA:\n",
    "    print(f\"  Diferenciación aplicada: orden {DIFF_ORDER}\")\n",
    "\n",
    "# Usar datos diferenciados si están disponibles\n",
    "data_for_production = df_diff if USE_DIFFERENCED_DATA else df\n",
    "\n",
    "# Obtener últimos valores originales para revertir diferenciación\n",
    "if USE_DIFFERENCED_DATA:\n",
    "    original_last_values = df_original.iloc[-1].values\n",
    "else:\n",
    "    original_last_values = None\n",
    "\n",
    "# Entrenar modelo final con todos los datos\n",
    "try:\n",
    "    forecast = var_forecast(\n",
    "        data_for_production, \n",
    "        order=best_order, \n",
    "        forecast_horizon=1,\n",
    "        use_differenced=USE_DIFFERENCED_DATA,\n",
    "        diff_order=DIFF_ORDER,\n",
    "        original_last_values=original_last_values\n",
    "    )\n",
    "    prediccion = forecast[0]  # [producto1, producto2]\n",
    "    \n",
    "    predicciones_produccion = {\n",
    "        'producto1': prediccion[0],\n",
    "        'producto2': prediccion[1]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nPredicciones para el siguiente mes:\")\n",
    "    print(f\"  producto1: {prediccion[0]:.4f}\")\n",
    "    print(f\"  producto2: {prediccion[1]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nÚltimos valores observados:\")\n",
    "    print(f\"  producto1: {df_original['producto1'].iloc[-1]:.4f}\")\n",
    "    print(f\"  producto2: {df_original['producto2'].iloc[-1]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nDiferencias:\")\n",
    "    print(f\"  producto1: {prediccion[0] - df_original['producto1'].iloc[-1]:.4f}\")\n",
    "    print(f\"  producto2: {prediccion[1] - df_original['producto2'].iloc[-1]:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al generar predicción: {e}\")\n",
    "    # Fallback: usar último valor\n",
    "    predicciones_produccion = {\n",
    "        'producto1': df_original['producto1'].iloc[-1],\n",
    "        'producto2': df_original['producto2'].iloc[-1]\n",
    "    }\n",
    "    print(f\"Predicción (fallback):\")\n",
    "    print(f\"  producto1: {predicciones_produccion['producto1']:.4f}\")\n",
    "    print(f\"  producto2: {predicciones_produccion['producto2']:.4f}\")\n",
    "\n",
    "# Mostrar resumen de predicciones\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN DE PREDICCIONES PARA PRODUCCIÓN\")\n",
    "print(\"=\" * 80)\n",
    "for producto, prediccion in predicciones_produccion.items():\n",
    "    print(f\"{producto}: {prediccion:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
