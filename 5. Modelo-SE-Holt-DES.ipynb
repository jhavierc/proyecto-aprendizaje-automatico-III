{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88658e38",
   "metadata": {},
   "source": [
    "# Modelo de Suavización Exponencial Doble - Holt (DES)\n",
    "\n",
    "Este notebook implementa el método de Suavización Exponencial Doble (Double Exponential Smoothing - Holt) para predecir las ventas de dos productos, utilizando tres tipos de validación temporal:\n",
    "- Walk-Forward Validation\n",
    "- Rolling Window\n",
    "- Expanding Window\n",
    "\n",
    "Posteriormente, se utiliza Optimización Bayesiana para encontrar los mejores hiperparámetros y entrenar el modelo final para producción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24aed950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import warnings\n",
    "import optuna\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708d172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado:\n",
      "Forma del dataset: (127, 2)\n",
      "\n",
      "Primeras filas:\n",
      "    producto1   producto2\n",
      "1  500.000000  200.000000\n",
      "2  497.400893  210.686220\n",
      "3  478.605317  222.018584\n",
      "4  486.454125  233.920990\n",
      "5  479.695678  238.402098\n",
      "\n",
      "Últimas filas:\n",
      "      producto1   producto2\n",
      "123  164.610771  629.293034\n",
      "124  150.881839  637.099467\n",
      "125  151.788470  653.155282\n",
      "126  137.047639  672.528345\n",
      "127  141.990873  676.058092\n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 127 entries, 1 to 127\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   producto1  127 non-null    float64\n",
      " 1   producto2  127 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 3.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('data-set.csv', index_col=0)\n",
    "print(\"Dataset cargado:\")\n",
    "print(f\"Forma del dataset: {df.shape}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "print(df.head())\n",
    "print(f\"\\nÚltimas filas:\")\n",
    "print(df.tail())\n",
    "print(f\"\\nInformación del dataset:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf1292",
   "metadata": {},
   "source": [
    "## Función Holt (Double Exponential Smoothing)\n",
    "\n",
    "Implementación del método de Suavización Exponencial Doble (Holt) para realizar predicciones. En Holt, se utilizan dos parámetros de suavización:\n",
    "- alpha (α): controla el peso dado a las observaciones más recientes del nivel\n",
    "- beta (β): controla el peso dado a las observaciones más recientes de la tendencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89628e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holt_forecast(data, alpha=None, beta=None, forecast_horizon=1):\n",
    "    \"\"\"\n",
    "    Calcula la Suavización Exponencial Doble (Holt) y realiza predicciones.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Serie temporal de datos\n",
    "    alpha : float, optional\n",
    "        Parámetro de suavización del nivel (0 < alpha <= 1). Si es None, se optimiza automáticamente.\n",
    "    beta : float, optional\n",
    "        Parámetro de suavización de la tendencia (0 < beta <= 1). Si es None, se optimiza automáticamente.\n",
    "    forecast_horizon : int\n",
    "        Número de períodos a predecir (por defecto 1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float or array\n",
    "        Predicción(es) usando Holt\n",
    "    \"\"\"\n",
    "    if len(data) < 2:\n",
    "        # Si no hay suficientes datos, usar el último valor disponible\n",
    "        return data[-1] if len(data) > 0 else 0\n",
    "    \n",
    "    # Convertir a pandas Series para usar con statsmodels\n",
    "    data_series = pd.Series(data)\n",
    "    \n",
    "    try:\n",
    "        # Crear y ajustar el modelo Holt\n",
    "        # Double Exponential Smoothing: trend='add', seasonal=None\n",
    "        model = ExponentialSmoothing(\n",
    "            data_series,\n",
    "            trend='add',\n",
    "            seasonal=None,\n",
    "            initialization_method='estimated'\n",
    "        )\n",
    "        \n",
    "        # Si alpha y beta son None, dejar que el modelo los optimice\n",
    "        # Si están especificados, usarlos\n",
    "        if alpha is not None and beta is not None:\n",
    "            fit = model.fit(smoothing_level=alpha, smoothing_trend=beta, optimized=False)\n",
    "        else:\n",
    "            fit = model.fit(optimized=True)\n",
    "        \n",
    "        # Realizar predicción\n",
    "        forecast = fit.forecast(steps=forecast_horizon)\n",
    "        \n",
    "        # Si solo se predice un paso, devolver un escalar\n",
    "        if forecast_horizon == 1:\n",
    "            # Manejar tanto Series como array\n",
    "            if hasattr(forecast, 'iloc'):\n",
    "                return float(forecast.iloc[0])\n",
    "            else:\n",
    "                return float(forecast[0])\n",
    "        else:\n",
    "            # Devolver array de predicciones\n",
    "            if hasattr(forecast, 'values'):\n",
    "                return forecast.values\n",
    "            else:\n",
    "                return np.array(forecast)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # En caso de error, usar el último valor como predicción\n",
    "        print(f\"Advertencia en Holt: {e}\")\n",
    "        return data[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce6aa5",
   "metadata": {},
   "source": [
    "## Función 1: Walk-Forward Validation\n",
    "    \n",
    "En Walk-Forward Validation, se entrena el modelo con datos hasta un punto específico y se valida con el siguiente punto. Luego se avanza un paso y se repite el proceso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ef8b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_validation(dataset, alpha=None, beta=None, train_size_min=12):\n",
    "    \"\"\"\n",
    "    Realiza validación Walk-Forward para cada producto del dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : pandas.DataFrame\n",
    "        Dataset con las columnas de productos\n",
    "    alpha : float, optional\n",
    "        Parámetro de suavización del nivel para Holt. Si es None, se optimiza en cada ventana.\n",
    "    beta : float, optional\n",
    "        Parámetro de suavización de la tendencia para Holt. Si es None, se optimiza en cada ventana.\n",
    "    train_size_min : int\n",
    "        Tamaño mínimo de entrenamiento antes de comenzar la validación (por defecto 12)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con métricas para cada producto:\n",
    "        - 'producto1': lista de diccionarios con métricas por iteración\n",
    "        - 'producto2': lista de diccionarios con métricas por iteración\n",
    "        Cada diccionario contiene: iteracion, ventana, rmse, mae\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for producto in dataset.columns:\n",
    "        print(f\"\\n=== Walk-Forward Validation para {producto} ===\")\n",
    "        data = dataset[producto].values\n",
    "        n = len(data)\n",
    "        \n",
    "        metrics_list = []\n",
    "        \n",
    "        # Comenzar validación desde train_size_min hasta n-1\n",
    "        for i in range(train_size_min, n):\n",
    "            # Datos de entrenamiento: desde el inicio hasta i\n",
    "            train_data = data[:i]\n",
    "            # Dato de validación: i\n",
    "            actual = data[i]\n",
    "            \n",
    "            # Realizar predicción\n",
    "            try:\n",
    "                prediction = holt_forecast(train_data, alpha=alpha, beta=beta, forecast_horizon=1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error en iteración {i}: {e}\")\n",
    "                prediction = train_data[-1]  # Fallback al último valor\n",
    "            \n",
    "            # Calcular métricas\n",
    "            rmse = np.sqrt(mean_squared_error([actual], [prediction]))\n",
    "            mae = mean_absolute_error([actual], [prediction])\n",
    "            \n",
    "            metrics_list.append({\n",
    "                'iteracion': i - train_size_min + 1,\n",
    "                'ventana': i,\n",
    "                'rmse': rmse,\n",
    "                'mae': mae\n",
    "            })\n",
    "            \n",
    "            if (i - train_size_min + 1) % 20 == 0:\n",
    "                print(f\"  Iteración {i - train_size_min + 1}/{n - train_size_min}: RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "        \n",
    "        results[producto] = metrics_list\n",
    "        print(f\"  Total de iteraciones: {len(metrics_list)}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9dc063",
   "metadata": {},
   "source": [
    "## Función 2: Rolling Window Validation\n",
    "\n",
    "En Rolling Window Validation, se mantiene un tamaño fijo de ventana de entrenamiento que se desplaza a lo largo del tiempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e81a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_validation(dataset, alpha=None, beta=None, train_window_size=12):\n",
    "    \"\"\"\n",
    "    Realiza validación Rolling Window para cada producto del dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : pandas.DataFrame\n",
    "        Dataset con las columnas de productos\n",
    "    alpha : float, optional\n",
    "        Parámetro de suavización del nivel para Holt. Si es None, se optimiza en cada ventana.\n",
    "    beta : float, optional\n",
    "        Parámetro de suavización de la tendencia para Holt. Si es None, se optimiza en cada ventana.\n",
    "    train_window_size : int\n",
    "        Tamaño fijo de la ventana de entrenamiento (por defecto 12)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con métricas para cada producto:\n",
    "        - 'producto1': lista de diccionarios con métricas por iteración\n",
    "        - 'producto2': lista de diccionarios con métricas por iteración\n",
    "        Cada diccionario contiene: iteracion, ventana, rmse, mae\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for producto in dataset.columns:\n",
    "        print(f\"\\n=== Rolling Window Validation para {producto} ===\")\n",
    "        data = dataset[producto].values\n",
    "        n = len(data)\n",
    "        \n",
    "        metrics_list = []\n",
    "        \n",
    "        # Comenzar desde train_window_size hasta n-1\n",
    "        for i in range(train_window_size, n):\n",
    "            # Datos de entrenamiento: ventana fija de tamaño train_window_size\n",
    "            train_data = data[i - train_window_size:i]\n",
    "            # Dato de validación: i\n",
    "            actual = data[i]\n",
    "            \n",
    "            # Realizar predicción\n",
    "            try:\n",
    "                prediction = holt_forecast(train_data, alpha=alpha, beta=beta, forecast_horizon=1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error en iteración {i}: {e}\")\n",
    "                prediction = train_data[-1]  # Fallback al último valor\n",
    "            \n",
    "            # Calcular métricas\n",
    "            rmse = np.sqrt(mean_squared_error([actual], [prediction]))\n",
    "            mae = mean_absolute_error([actual], [prediction])\n",
    "            \n",
    "            metrics_list.append({\n",
    "                'iteracion': i - train_window_size + 1,\n",
    "                'ventana': f\"{i - train_window_size}-{i}\",\n",
    "                'rmse': rmse,\n",
    "                'mae': mae\n",
    "            })\n",
    "            \n",
    "            if (i - train_window_size + 1) % 20 == 0:\n",
    "                print(f\"  Iteración {i - train_window_size + 1}/{n - train_window_size}: RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "        \n",
    "        results[producto] = metrics_list\n",
    "        print(f\"  Total de iteraciones: {len(metrics_list)}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd83ce",
   "metadata": {},
   "source": [
    "## Función 3: Expanding Window Validation\n",
    "\n",
    "En Expanding Window Validation, la ventana de entrenamiento crece con cada iteración, comenzando desde un tamaño mínimo y expandiéndose hasta incluir todos los datos disponibles hasta ese punto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5d6eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_window_validation(dataset, alpha=None, beta=None, train_size_min=12):\n",
    "    \"\"\"\n",
    "    Realiza validación Expanding Window para cada producto del dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : pandas.DataFrame\n",
    "        Dataset con las columnas de productos\n",
    "    alpha : float, optional\n",
    "        Parámetro de suavización del nivel para Holt. Si es None, se optimiza en cada ventana.\n",
    "    beta : float, optional\n",
    "        Parámetro de suavización de la tendencia para Holt. Si es None, se optimiza en cada ventana.\n",
    "    train_size_min : int\n",
    "        Tamaño mínimo inicial de la ventana de entrenamiento (por defecto 12)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con métricas para cada producto:\n",
    "        - 'producto1': lista de diccionarios con métricas por iteración\n",
    "        - 'producto2': lista de diccionarios con métricas por iteración\n",
    "        Cada diccionario contiene: iteracion, ventana, rmse, mae\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for producto in dataset.columns:\n",
    "        print(f\"\\n=== Expanding Window Validation para {producto} ===\")\n",
    "        data = dataset[producto].values\n",
    "        n = len(data)\n",
    "        \n",
    "        metrics_list = []\n",
    "        \n",
    "        # Comenzar validación desde train_size_min hasta n-1\n",
    "        for i in range(train_size_min, n):\n",
    "            # Datos de entrenamiento: desde el inicio hasta i (ventana que se expande)\n",
    "            train_data = data[:i]\n",
    "            # Dato de validación: i\n",
    "            actual = data[i]\n",
    "            \n",
    "            # Realizar predicción\n",
    "            try:\n",
    "                prediction = holt_forecast(train_data, alpha=alpha, beta=beta, forecast_horizon=1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error en iteración {i}: {e}\")\n",
    "                prediction = train_data[-1]  # Fallback al último valor\n",
    "            \n",
    "            # Calcular métricas\n",
    "            rmse = np.sqrt(mean_squared_error([actual], [prediction]))\n",
    "            mae = mean_absolute_error([actual], [prediction])\n",
    "            \n",
    "            metrics_list.append({\n",
    "                'iteracion': i - train_size_min + 1,\n",
    "                'ventana': i,  # Tamaño de la ventana que se expande\n",
    "                'rmse': rmse,\n",
    "                'mae': mae\n",
    "            })\n",
    "            \n",
    "            if (i - train_size_min + 1) % 20 == 0:\n",
    "                print(f\"  Iteración {i - train_size_min + 1}/{n - train_size_min}: RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "        \n",
    "        results[producto] = metrics_list\n",
    "        print(f\"  Total de iteraciones: {len(metrics_list)}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d057d",
   "metadata": {},
   "source": [
    "## Ejecución de las Validaciones\n",
    "\n",
    "Después de definir las funciones que permitirán ejecutar el modelo teniendo en cuenta los tres tipos de validación, ahora ejecutamos las tres validaciones para cada producto y calculamos las métricas promedio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0978fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "WALK-FORWARD VALIDATION\n",
      "============================================================\n",
      "\n",
      "=== Walk-Forward Validation para producto1 ===\n",
      "  Iteración 20/115: RMSE=1.4133, MAE=1.4133\n",
      "  Iteración 40/115: RMSE=6.7388, MAE=6.7388\n",
      "  Iteración 60/115: RMSE=8.9019, MAE=8.9019\n",
      "  Iteración 80/115: RMSE=8.2118, MAE=8.2118\n",
      "  Iteración 100/115: RMSE=15.1311, MAE=15.1311\n",
      "  Total de iteraciones: 115\n",
      "\n",
      "=== Walk-Forward Validation para producto2 ===\n",
      "  Iteración 20/115: RMSE=12.9458, MAE=12.9458\n",
      "  Iteración 40/115: RMSE=7.4010, MAE=7.4010\n",
      "  Iteración 60/115: RMSE=1.4761, MAE=1.4761\n",
      "  Iteración 80/115: RMSE=26.1809, MAE=26.1809\n",
      "  Iteración 100/115: RMSE=8.3415, MAE=8.3415\n",
      "  Total de iteraciones: 115\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de validación\n",
    "TRAIN_SIZE_MIN = 12  # Tamaño mínimo de entrenamiento\n",
    "TRAIN_WINDOW_SIZE = 12  # Tamaño fijo para Rolling Window\n",
    "\n",
    "# Ejecutar Walk-Forward Validation\n",
    "print(\"=\" * 60)\n",
    "print(\"WALK-FORWARD VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "results_wf = walk_forward_validation(df, alpha=None, beta=None, train_size_min=TRAIN_SIZE_MIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab7fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ROLLING WINDOW VALIDATION\n",
      "============================================================\n",
      "\n",
      "=== Rolling Window Validation para producto1 ===\n",
      "  Iteración 20/115: RMSE=1.6922, MAE=1.6922\n",
      "  Iteración 40/115: RMSE=2.7692, MAE=2.7692\n",
      "  Iteración 60/115: RMSE=1.5471, MAE=1.5471\n",
      "  Iteración 80/115: RMSE=14.3658, MAE=14.3658\n",
      "  Iteración 100/115: RMSE=10.0089, MAE=10.0089\n",
      "  Total de iteraciones: 115\n",
      "\n",
      "=== Rolling Window Validation para producto2 ===\n",
      "  Iteración 20/115: RMSE=14.8344, MAE=14.8344\n",
      "  Iteración 40/115: RMSE=9.8621, MAE=9.8621\n",
      "  Iteración 60/115: RMSE=8.6249, MAE=8.6249\n",
      "  Iteración 80/115: RMSE=38.8432, MAE=38.8432\n",
      "  Iteración 100/115: RMSE=10.5202, MAE=10.5202\n",
      "  Total de iteraciones: 115\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar Rolling Window Validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ROLLING WINDOW VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "results_rw = rolling_window_validation(df, alpha=None, beta=None, train_window_size=TRAIN_WINDOW_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef2d8a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPANDING WINDOW VALIDATION\n",
      "============================================================\n",
      "\n",
      "=== Expanding Window Validation para producto1 ===\n",
      "  Iteración 20/115: RMSE=1.4133, MAE=1.4133\n",
      "  Iteración 40/115: RMSE=6.7388, MAE=6.7388\n",
      "  Iteración 60/115: RMSE=8.9019, MAE=8.9019\n",
      "  Iteración 80/115: RMSE=8.2118, MAE=8.2118\n",
      "  Iteración 100/115: RMSE=15.1311, MAE=15.1311\n",
      "  Total de iteraciones: 115\n",
      "\n",
      "=== Expanding Window Validation para producto2 ===\n",
      "  Iteración 20/115: RMSE=12.9458, MAE=12.9458\n",
      "  Iteración 40/115: RMSE=7.4010, MAE=7.4010\n",
      "  Iteración 60/115: RMSE=1.4761, MAE=1.4761\n",
      "  Iteración 80/115: RMSE=26.1809, MAE=26.1809\n",
      "  Iteración 100/115: RMSE=8.3415, MAE=8.3415\n",
      "  Total de iteraciones: 115\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar Expanding Window Validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPANDING WINDOW VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "results_ew = expanding_window_validation(df, alpha=None, beta=None, train_size_min=TRAIN_SIZE_MIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596f235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MÉTRICAS PROMEDIO - WALK-FORWARD\n",
      "============================================================\n",
      "\n",
      "producto1:\n",
      "  RMSE Promedio: 7.0768\n",
      "  MAE Promedio: 7.0768\n",
      "  Número de iteraciones: 115\n",
      "\n",
      "producto2:\n",
      "  RMSE Promedio: 12.2762\n",
      "  MAE Promedio: 12.2762\n",
      "  Número de iteraciones: 115\n",
      "\n",
      "============================================================\n",
      "MÉTRICAS PROMEDIO - ROLLING WINDOW\n",
      "============================================================\n",
      "\n",
      "producto1:\n",
      "  RMSE Promedio: 7.3847\n",
      "  MAE Promedio: 7.3847\n",
      "  Número de iteraciones: 115\n",
      "\n",
      "producto2:\n",
      "  RMSE Promedio: 12.4054\n",
      "  MAE Promedio: 12.4054\n",
      "  Número de iteraciones: 115\n",
      "\n",
      "============================================================\n",
      "MÉTRICAS PROMEDIO - EXPANDING WINDOW\n",
      "============================================================\n",
      "\n",
      "producto1:\n",
      "  RMSE Promedio: 7.0768\n",
      "  MAE Promedio: 7.0768\n",
      "  Número de iteraciones: 115\n",
      "\n",
      "producto2:\n",
      "  RMSE Promedio: 12.2762\n",
      "  MAE Promedio: 12.2762\n",
      "  Número de iteraciones: 115\n"
     ]
    }
   ],
   "source": [
    "def calcular_metricas_promedio(results, nombre_validacion):\n",
    "    \"\"\"\n",
    "    Calcula las métricas promedio para cada producto.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Resultados de la validación\n",
    "    nombre_validacion : str\n",
    "        Nombre del tipo de validación\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con métricas promedio por producto\n",
    "    \"\"\"\n",
    "    metricas_promedio = {}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MÉTRICAS PROMEDIO - {nombre_validacion.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for producto in results.keys():\n",
    "        metrics_list = results[producto]\n",
    "        \n",
    "        # Calcular promedios\n",
    "        rmse_promedio = np.mean([m['rmse'] for m in metrics_list])\n",
    "        mae_promedio = np.mean([m['mae'] for m in metrics_list])\n",
    "        \n",
    "        metricas_promedio[producto] = {\n",
    "            'rmse_promedio': rmse_promedio,\n",
    "            'mae_promedio': mae_promedio,\n",
    "            'num_iteraciones': len(metrics_list)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{producto}:\")\n",
    "        print(f\"  RMSE Promedio: {rmse_promedio:.4f}\")\n",
    "        print(f\"  MAE Promedio: {mae_promedio:.4f}\")\n",
    "        print(f\"  Número de iteraciones: {len(metrics_list)}\")\n",
    "    \n",
    "    return metricas_promedio\n",
    "\n",
    "# Calcular métricas promedio para cada tipo de validación\n",
    "metricas_wf = calcular_metricas_promedio(results_wf, \"Walk-Forward\")\n",
    "metricas_rw = calcular_metricas_promedio(results_rw, \"Rolling Window\")\n",
    "metricas_ew = calcular_metricas_promedio(results_ew, \"Expanding Window\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed00e3d",
   "metadata": {},
   "source": [
    "## Comparación de Resultados y Selección del Mejor Método de Validación\n",
    "\n",
    "Comparamos los RMSE promedio de cada tipo de validación para seleccionar el mejor método.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d382968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARACIÓN DE MÉTODOS DE VALIDACIÓN\n",
      "================================================================================\n",
      " Producto       Validacion  RMSE_Promedio  MAE_Promedio\n",
      "producto1     Walk-Forward       7.076816      7.076816\n",
      "producto1   Rolling Window       7.384706      7.384706\n",
      "producto1 Expanding Window       7.076814      7.076814\n",
      "producto2     Walk-Forward      12.276188     12.276188\n",
      "producto2   Rolling Window      12.405437     12.405437\n",
      "producto2 Expanding Window      12.276187     12.276187\n",
      "\n",
      "================================================================================\n",
      "MEJOR MÉTODO DE VALIDACIÓN POR PRODUCTO (basado en RMSE Promedio)\n",
      "================================================================================\n",
      "\n",
      "producto1:\n",
      "  Mejor método: Expanding Window\n",
      "  RMSE Promedio: 7.0768\n",
      "\n",
      "producto2:\n",
      "  Mejor método: Expanding Window\n",
      "  RMSE Promedio: 12.2762\n"
     ]
    }
   ],
   "source": [
    "# Crear DataFrame comparativo\n",
    "comparacion = []\n",
    "\n",
    "for producto in df.columns:\n",
    "    comparacion.append({\n",
    "        'Producto': producto,\n",
    "        'Validacion': 'Walk-Forward',\n",
    "        'RMSE_Promedio': metricas_wf[producto]['rmse_promedio'],\n",
    "        'MAE_Promedio': metricas_wf[producto]['mae_promedio']\n",
    "    })\n",
    "    comparacion.append({\n",
    "        'Producto': producto,\n",
    "        'Validacion': 'Rolling Window',\n",
    "        'RMSE_Promedio': metricas_rw[producto]['rmse_promedio'],\n",
    "        'MAE_Promedio': metricas_rw[producto]['mae_promedio']\n",
    "    })\n",
    "    comparacion.append({\n",
    "        'Producto': producto,\n",
    "        'Validacion': 'Expanding Window',\n",
    "        'RMSE_Promedio': metricas_ew[producto]['rmse_promedio'],\n",
    "        'MAE_Promedio': metricas_ew[producto]['mae_promedio']\n",
    "    })\n",
    "\n",
    "df_comparacion = pd.DataFrame(comparacion)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARACIÓN DE MÉTODOS DE VALIDACIÓN\")\n",
    "print(\"=\" * 80)\n",
    "print(df_comparacion.to_string(index=False))\n",
    "\n",
    "# Identificar el mejor método para cada producto\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MEJOR MÉTODO DE VALIDACIÓN POR PRODUCTO (basado en RMSE Promedio)\")\n",
    "print(\"=\" * 80)\n",
    "for producto in df.columns:\n",
    "    producto_df = df_comparacion[df_comparacion['Producto'] == producto]\n",
    "    mejor = producto_df.loc[producto_df['RMSE_Promedio'].idxmin()]\n",
    "    print(f\"\\n{producto}:\")\n",
    "    print(f\"  Mejor método: {mejor['Validacion']}\")\n",
    "    print(f\"  RMSE Promedio: {mejor['RMSE_Promedio']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791a622",
   "metadata": {},
   "source": [
    "## Optimización Bayesiana para Encontrar los Mejores Parámetros (Alpha y Beta)\n",
    "\n",
    "Utilizamos Optimización Bayesiana (Optuna) para encontrar los mejores parámetros alpha y beta para cada producto, usando el mejor método de validación identificado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "402f90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_walk_forward(trial, data, train_size_min=12):\n",
    "    \"\"\"\n",
    "    Función objetivo para optimización bayesiana usando Walk-Forward Validation.\n",
    "    \"\"\"\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 0.99, log=False)\n",
    "    beta = trial.suggest_float('beta', 0.01, 0.99, log=False)\n",
    "    \n",
    "    n = len(data)\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(train_size_min, n):\n",
    "        train_data = data[:i]\n",
    "        actual = data[i]\n",
    "        \n",
    "        try:\n",
    "            prediction = holt_forecast(train_data, alpha=alpha, beta=beta, forecast_horizon=1)\n",
    "            error = np.sqrt(mean_squared_error([actual], [prediction]))\n",
    "            if np.isfinite(error):\n",
    "                errors.append(error)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(errors) == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    return np.mean(errors)\n",
    "\n",
    "def objective_rolling_window(trial, data, train_window_size=12):\n",
    "    \"\"\"\n",
    "    Función objetivo para optimización bayesiana usando Rolling Window Validation.\n",
    "    \"\"\"\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 0.99, log=False)\n",
    "    beta = trial.suggest_float('beta', 0.01, 0.99, log=False)\n",
    "    \n",
    "    n = len(data)\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(train_window_size, n):\n",
    "        train_data = data[i - train_window_size:i]\n",
    "        actual = data[i]\n",
    "        \n",
    "        try:\n",
    "            prediction = holt_forecast(train_data, alpha=alpha, beta=beta, forecast_horizon=1)\n",
    "            error = np.sqrt(mean_squared_error([actual], [prediction]))\n",
    "            if np.isfinite(error):\n",
    "                errors.append(error)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(errors) == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    return np.mean(errors)\n",
    "\n",
    "def objective_expanding_window(trial, data, train_size_min=12):\n",
    "    \"\"\"\n",
    "    Función objetivo para optimización bayesiana usando Expanding Window Validation.\n",
    "    \"\"\"\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 0.99, log=False)\n",
    "    beta = trial.suggest_float('beta', 0.01, 0.99, log=False)\n",
    "    \n",
    "    n = len(data)\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(train_size_min, n):\n",
    "        train_data = data[:i]\n",
    "        actual = data[i]\n",
    "        \n",
    "        try:\n",
    "            prediction = holt_forecast(train_data, alpha=alpha, beta=beta, forecast_horizon=1)\n",
    "            error = np.sqrt(mean_squared_error([actual], [prediction]))\n",
    "            if np.isfinite(error):\n",
    "                errors.append(error)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(errors) == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    return np.mean(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62bfb60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 13:13:14,826] A new study created in memory with name: no-name-8e343e22-3f43-4e81-8c66-bc1e2c892091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producto1: Mejor método = Expanding Window\n",
      "producto2: Mejor método = Expanding Window\n",
      "\n",
      "================================================================================\n",
      "OPTIMIZACIÓN BAYESIANA\n",
      "================================================================================\n",
      "\n",
      "--- Optimizando producto1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112ec0ef17ef466f96ce76280d1bb611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 13:13:15,118] Trial 0 finished with value: 6.581963061261775 and parameters: {'alpha': 0.7489757122687674, 'beta': 0.40588177962994315}. Best is trial 0 with value: 6.581963061261775.\n",
      "[I 2025-11-30 13:13:15,398] Trial 1 finished with value: 6.961734083681842 and parameters: {'alpha': 0.5505044242468033, 'beta': 0.4113632679611899}. Best is trial 0 with value: 6.581963061261775.\n",
      "[I 2025-11-30 13:13:15,965] Trial 2 finished with value: 26.05371877200114 and parameters: {'alpha': 0.1378265562280264, 'beta': 0.16116481576294633}. Best is trial 0 with value: 6.581963061261775.\n",
      "[I 2025-11-30 13:13:16,286] Trial 3 finished with value: 6.987057956650726 and parameters: {'alpha': 0.8422398393727549, 'beta': 0.5614940043492134}. Best is trial 0 with value: 6.581963061261775.\n",
      "[I 2025-11-30 13:13:16,606] Trial 4 finished with value: 7.156981301921848 and parameters: {'alpha': 0.97337858687094, 'beta': 0.1909790748243071}. Best is trial 0 with value: 6.581963061261775.\n",
      "[I 2025-11-30 13:13:16,908] Trial 5 finished with value: 6.901469882904124 and parameters: {'alpha': 0.7377477099398283, 'beta': 0.23014482717212742}. Best is trial 0 with value: 6.581963061261775.\n",
      "[I 2025-11-30 13:13:17,147] Trial 6 finished with value: 9.969103660414786 and parameters: {'alpha': 0.30877674716461717, 'beta': 0.4218396176944979}. Best is trial 0 with value: 6.581963061261775.\n",
      "[I 2025-11-30 13:13:17,382] Trial 7 finished with value: 58.183313210220795 and parameters: {'alpha': 0.03022952623286887, 'beta': 0.13540541728053399}. Best is trial 0 with value: 6.581963061261775.\n",
      "[I 2025-11-30 13:13:17,613] Trial 8 finished with value: 6.512219971231031 and parameters: {'alpha': 0.7024502268832639, 'beta': 0.5535338708163257}. Best is trial 8 with value: 6.512219971231031.\n",
      "[I 2025-11-30 13:13:17,847] Trial 9 finished with value: 14.053017201003408 and parameters: {'alpha': 0.16892913631267792, 'beta': 0.9509758108383188}. Best is trial 8 with value: 6.512219971231031.\n",
      "[I 2025-11-30 13:13:18,085] Trial 10 finished with value: 6.614259086769271 and parameters: {'alpha': 0.4674986338109926, 'beta': 0.7733037953905433}. Best is trial 8 with value: 6.512219971231031.\n",
      "[I 2025-11-30 13:13:18,326] Trial 11 finished with value: 6.459247757908297 and parameters: {'alpha': 0.6607493460995363, 'beta': 0.6111387999232927}. Best is trial 11 with value: 6.459247757908297.\n",
      "[I 2025-11-30 13:13:18,638] Trial 12 finished with value: 6.389500695079054 and parameters: {'alpha': 0.6040802015883495, 'beta': 0.6918013150170856}. Best is trial 12 with value: 6.389500695079054.\n",
      "[I 2025-11-30 13:13:18,878] Trial 13 finished with value: 6.3960916760930955 and parameters: {'alpha': 0.5241099414333453, 'beta': 0.7400109074660333}. Best is trial 12 with value: 6.389500695079054.\n",
      "[I 2025-11-30 13:13:19,131] Trial 14 finished with value: 7.221755738650741 and parameters: {'alpha': 0.399713089567299, 'beta': 0.7635623734258201}. Best is trial 12 with value: 6.389500695079054.\n",
      "[I 2025-11-30 13:13:19,526] Trial 15 finished with value: 6.360031327414649 and parameters: {'alpha': 0.5699088999009766, 'beta': 0.74105111134502}. Best is trial 15 with value: 6.360031327414649.\n",
      "[I 2025-11-30 13:13:19,834] Trial 16 finished with value: 6.522804017209578 and parameters: {'alpha': 0.5882208001415867, 'beta': 0.9742513123086787}. Best is trial 15 with value: 6.360031327414649.\n",
      "[I 2025-11-30 13:13:20,149] Trial 17 finished with value: 7.344758972394742 and parameters: {'alpha': 0.3644627683901826, 'beta': 0.8679123558649201}. Best is trial 15 with value: 6.360031327414649.\n",
      "[I 2025-11-30 13:13:20,392] Trial 18 finished with value: 7.404461813735807 and parameters: {'alpha': 0.8686445352367298, 'beta': 0.6727010341015643}. Best is trial 15 with value: 6.360031327414649.\n",
      "[I 2025-11-30 13:13:20,630] Trial 19 finished with value: 8.948373788052074 and parameters: {'alpha': 0.28208060716207894, 'beta': 0.8493653201027872}. Best is trial 15 with value: 6.360031327414649.\n",
      "[I 2025-11-30 13:13:20,867] Trial 20 finished with value: 9.340471339333705 and parameters: {'alpha': 0.6271330505295298, 'beta': 0.018859936887344275}. Best is trial 15 with value: 6.360031327414649.\n",
      "[I 2025-11-30 13:13:21,110] Trial 21 finished with value: 6.475693620344583 and parameters: {'alpha': 0.5149400793519182, 'beta': 0.711375093292034}. Best is trial 15 with value: 6.360031327414649.\n",
      "[I 2025-11-30 13:13:21,347] Trial 22 finished with value: 7.119491603935339 and parameters: {'alpha': 0.4441691547411921, 'beta': 0.6431976073102329}. Best is trial 15 with value: 6.360031327414649.\n",
      "[I 2025-11-30 13:13:21,583] Trial 23 finished with value: 6.352652947895596 and parameters: {'alpha': 0.5424429527391909, 'beta': 0.849552819697044}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:21,826] Trial 24 finished with value: 7.326865579940502 and parameters: {'alpha': 0.7949189845479374, 'beta': 0.8465937222646722}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:22,063] Trial 25 finished with value: 6.543968088592111 and parameters: {'alpha': 0.6186452432145126, 'beta': 0.8986660558780202}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:22,302] Trial 26 finished with value: 6.660526186653182 and parameters: {'alpha': 0.6826147539448103, 'beta': 0.8005794099482028}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:22,537] Trial 27 finished with value: 7.380075487725234 and parameters: {'alpha': 0.4508941716195486, 'beta': 0.5255917136756607}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:22,779] Trial 28 finished with value: 6.376690720612827 and parameters: {'alpha': 0.5793989794931996, 'beta': 0.6940764066148639}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:23,023] Trial 29 finished with value: 8.625528781106421 and parameters: {'alpha': 0.3647465781111274, 'beta': 0.4774364618142195}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:23,258] Trial 30 finished with value: 7.343952256728815 and parameters: {'alpha': 0.773247280546466, 'beta': 0.9196966637894196}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:23,491] Trial 31 finished with value: 6.391164781911394 and parameters: {'alpha': 0.557866468828495, 'beta': 0.6876087288646439}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:23,726] Trial 32 finished with value: 6.4220727134271565 and parameters: {'alpha': 0.5881287516151286, 'beta': 0.6090310042502536}. Best is trial 23 with value: 6.352652947895596.\n",
      "[I 2025-11-30 13:13:23,963] Trial 33 finished with value: 6.3428099395184985 and parameters: {'alpha': 0.5281643477385204, 'beta': 0.8108993506015586}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:24,214] Trial 34 finished with value: 6.389546262089094 and parameters: {'alpha': 0.5019590284010762, 'beta': 0.7979696753007257}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:24,450] Trial 35 finished with value: 12.392868771599632 and parameters: {'alpha': 0.24860659685059006, 'beta': 0.30835383713136266}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:24,692] Trial 36 finished with value: 7.000687878187194 and parameters: {'alpha': 0.40717321410707913, 'beta': 0.8143593859110202}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:24,927] Trial 37 finished with value: 7.030706592797875 and parameters: {'alpha': 0.7285933909285695, 'beta': 0.912887780142297}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:25,166] Trial 38 finished with value: 6.437603267284925 and parameters: {'alpha': 0.5512032790437087, 'beta': 0.9860220407200979}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:25,404] Trial 39 finished with value: 7.518144284332514 and parameters: {'alpha': 0.858164954276504, 'beta': 0.7400861908929108}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:25,640] Trial 40 finished with value: 6.4574140577309596 and parameters: {'alpha': 0.6603973179629175, 'beta': 0.6043351038353002}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:25,883] Trial 41 finished with value: 6.39481224460299 and parameters: {'alpha': 0.6067347032270786, 'beta': 0.7052518230372613}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:26,120] Trial 42 finished with value: 6.855643933923266 and parameters: {'alpha': 0.5465591728067859, 'beta': 0.46145695836211786}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:26,361] Trial 43 finished with value: 6.7956499822532255 and parameters: {'alpha': 0.48172732007331237, 'beta': 0.6526878103351776}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:26,790] Trial 44 finished with value: 6.728394568086445 and parameters: {'alpha': 0.6481897412074951, 'beta': 0.3486571427625091}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:27,074] Trial 45 finished with value: 6.54501900374131 and parameters: {'alpha': 0.715339540363192, 'beta': 0.5682348167265956}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:27,315] Trial 46 finished with value: 6.358704566954765 and parameters: {'alpha': 0.5665042305631526, 'beta': 0.7432174051357423}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:27,549] Trial 47 finished with value: 7.070243254530046 and parameters: {'alpha': 0.41729298288671524, 'beta': 0.7514060236067167}. Best is trial 33 with value: 6.3428099395184985.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 13:13:28,025] A new study created in memory with name: no-name-279c602b-6d00-4278-abfb-534c88fe90f2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 13:13:27,786] Trial 48 finished with value: 6.377868695835995 and parameters: {'alpha': 0.4964985839123986, 'beta': 0.826283933025832}. Best is trial 33 with value: 6.3428099395184985.\n",
      "[I 2025-11-30 13:13:28,022] Trial 49 finished with value: 6.3890959210965645 and parameters: {'alpha': 0.5608977949947651, 'beta': 0.8724512751167}. Best is trial 33 with value: 6.3428099395184985.\n",
      "  Mejor alpha: 0.5282\n",
      "  Mejor beta: 0.8109\n",
      "  Mejor RMSE: 6.3428\n",
      "  Método usado: Expanding Window\n",
      "\n",
      "--- Optimizando producto2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d7e2b087f54804b8d959ec1d5a87a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 13:13:28,269] Trial 0 finished with value: 21.677645188437022 and parameters: {'alpha': 0.2317436787870574, 'beta': 0.14470750953279854}. Best is trial 0 with value: 21.677645188437022.\n",
      "[I 2025-11-30 13:13:28,508] Trial 1 finished with value: 13.190621655692796 and parameters: {'alpha': 0.7560134566173258, 'beta': 0.9174157735436176}. Best is trial 1 with value: 13.190621655692796.\n",
      "[I 2025-11-30 13:13:28,743] Trial 2 finished with value: 58.95345361139687 and parameters: {'alpha': 0.03329954885647253, 'beta': 0.056302211559730884}. Best is trial 1 with value: 13.190621655692796.\n",
      "[I 2025-11-30 13:13:29,044] Trial 3 finished with value: 30.863915795956565 and parameters: {'alpha': 0.0741459420455869, 'beta': 0.11141830189019968}. Best is trial 1 with value: 13.190621655692796.\n",
      "[I 2025-11-30 13:13:29,333] Trial 4 finished with value: 31.05536392930096 and parameters: {'alpha': 0.0703845903769824, 'beta': 0.12969735642545738}. Best is trial 1 with value: 13.190621655692796.\n",
      "[I 2025-11-30 13:13:29,573] Trial 5 finished with value: 15.02561654491353 and parameters: {'alpha': 0.3360719828579853, 'beta': 0.47673793338208403}. Best is trial 1 with value: 13.190621655692796.\n",
      "[I 2025-11-30 13:13:29,914] Trial 6 finished with value: 11.441768035225076 and parameters: {'alpha': 0.588668977754384, 'beta': 0.5698160851880569}. Best is trial 6 with value: 11.441768035225076.\n",
      "[I 2025-11-30 13:13:30,199] Trial 7 finished with value: 12.646131472160354 and parameters: {'alpha': 0.8844781481523594, 'beta': 0.24378463505357922}. Best is trial 6 with value: 11.441768035225076.\n",
      "[I 2025-11-30 13:13:30,434] Trial 8 finished with value: 14.01833434080991 and parameters: {'alpha': 0.4222537699989629, 'beta': 0.33690320743366803}. Best is trial 6 with value: 11.441768035225076.\n",
      "[I 2025-11-30 13:13:30,665] Trial 9 finished with value: 12.075963932785683 and parameters: {'alpha': 0.6974099581506468, 'beta': 0.2681579466380615}. Best is trial 6 with value: 11.441768035225076.\n",
      "[I 2025-11-30 13:13:30,904] Trial 10 finished with value: 11.525608515565024 and parameters: {'alpha': 0.6150904313882499, 'beta': 0.7517750790103792}. Best is trial 6 with value: 11.441768035225076.\n",
      "[I 2025-11-30 13:13:31,139] Trial 11 finished with value: 11.449666831710672 and parameters: {'alpha': 0.5915512446793976, 'beta': 0.7736292286847744}. Best is trial 6 with value: 11.441768035225076.\n",
      "[I 2025-11-30 13:13:31,374] Trial 12 finished with value: 11.37345745373722 and parameters: {'alpha': 0.5476909345729998, 'beta': 0.6722463691920917}. Best is trial 12 with value: 11.37345745373722.\n",
      "[I 2025-11-30 13:13:31,608] Trial 13 finished with value: 11.599262616004031 and parameters: {'alpha': 0.49980125147016474, 'beta': 0.5801368502451559}. Best is trial 12 with value: 11.37345745373722.\n",
      "[I 2025-11-30 13:13:31,843] Trial 14 finished with value: 14.256249080886608 and parameters: {'alpha': 0.928093894426226, 'beta': 0.5858813370589876}. Best is trial 12 with value: 11.37345745373722.\n",
      "[I 2025-11-30 13:13:32,089] Trial 15 finished with value: 12.91749508009172 and parameters: {'alpha': 0.7999935219810435, 'beta': 0.6949331841330096}. Best is trial 12 with value: 11.37345745373722.\n",
      "[I 2025-11-30 13:13:32,325] Trial 16 finished with value: 11.8763935480253 and parameters: {'alpha': 0.3905884742124093, 'beta': 0.9063802676669863}. Best is trial 12 with value: 11.37345745373722.\n",
      "[I 2025-11-30 13:13:32,560] Trial 17 finished with value: 11.766536706999345 and parameters: {'alpha': 0.5690759527751589, 'beta': 0.4258045549312458}. Best is trial 12 with value: 11.37345745373722.\n",
      "[I 2025-11-30 13:13:32,861] Trial 18 finished with value: 16.194362232133393 and parameters: {'alpha': 0.28018473970876, 'beta': 0.6004693855833404}. Best is trial 12 with value: 11.37345745373722.\n",
      "[I 2025-11-30 13:13:33,100] Trial 19 finished with value: 11.309461475392725 and parameters: {'alpha': 0.48540160534578103, 'beta': 0.8427669745374304}. Best is trial 19 with value: 11.309461475392725.\n",
      "[I 2025-11-30 13:13:33,345] Trial 20 finished with value: 11.307802449077604 and parameters: {'alpha': 0.45283286377325915, 'beta': 0.9881751581251115}. Best is trial 20 with value: 11.307802449077604.\n",
      "[I 2025-11-30 13:13:33,580] Trial 21 finished with value: 11.473170768363193 and parameters: {'alpha': 0.42057671408299446, 'beta': 0.9761707928369836}. Best is trial 20 with value: 11.307802449077604.\n",
      "[I 2025-11-30 13:13:33,817] Trial 22 finished with value: 11.307313541129759 and parameters: {'alpha': 0.5111109864625443, 'beta': 0.8316619990649391}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:34,061] Trial 23 finished with value: 19.7457737762548 and parameters: {'alpha': 0.19537254399101117, 'beta': 0.8593096775681329}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:34,301] Trial 24 finished with value: 11.356602212058075 and parameters: {'alpha': 0.48443908731762064, 'beta': 0.7856931626687049}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:34,680] Trial 25 finished with value: 12.363436187716303 and parameters: {'alpha': 0.6744145219513631, 'beta': 0.989454784103212}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:34,920] Trial 26 finished with value: 12.530922906141484 and parameters: {'alpha': 0.35467453176281805, 'beta': 0.8424801181545766}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:35,215] Trial 27 finished with value: 11.362416151774951 and parameters: {'alpha': 0.46098644799421173, 'beta': 0.8684005038373722}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:35,621] Trial 28 finished with value: 21.979759276625767 and parameters: {'alpha': 0.16218374322377416, 'beta': 0.691969671201703}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:35,953] Trial 29 finished with value: 14.678552170148174 and parameters: {'alpha': 0.2585326643575564, 'beta': 0.9633765346340923}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:36,388] Trial 30 finished with value: 11.933821902596687 and parameters: {'alpha': 0.6616756680331494, 'beta': 0.8271935267638729}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:36,762] Trial 31 finished with value: 11.31443921229942 and parameters: {'alpha': 0.5050050625942445, 'beta': 0.793353212901521}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:37,104] Trial 32 finished with value: 11.308772063688487 and parameters: {'alpha': 0.5145759907220777, 'beta': 0.90185926792238}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:37,420] Trial 33 finished with value: 12.720357000446498 and parameters: {'alpha': 0.3362097892752096, 'beta': 0.9066806932311384}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:37,657] Trial 34 finished with value: 11.36084281488314 and parameters: {'alpha': 0.5331448002999996, 'beta': 0.9247404696791148}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:37,897] Trial 35 finished with value: 12.338019640157116 and parameters: {'alpha': 0.7351832868552057, 'beta': 0.7312460278926596}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:38,173] Trial 36 finished with value: 11.39365976029489 and parameters: {'alpha': 0.443330336712737, 'beta': 0.9239343315880131}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:38,527] Trial 37 finished with value: 13.850398760454098 and parameters: {'alpha': 0.3007550423954909, 'beta': 0.8247851355042042}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:38,846] Trial 38 finished with value: 11.509589416676345 and parameters: {'alpha': 0.6304324118691224, 'beta': 0.6432510958162856}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:39,094] Trial 39 finished with value: 13.655354929588785 and parameters: {'alpha': 0.38263439365935603, 'beta': 0.49569273387414425}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:39,397] Trial 40 finished with value: 11.352664061279484 and parameters: {'alpha': 0.45797942971949346, 'beta': 0.8927381462391012}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:39,737] Trial 41 finished with value: 11.325796956276621 and parameters: {'alpha': 0.5303606563442863, 'beta': 0.7984721228344015}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:39,977] Trial 42 finished with value: 15.382115204729368 and parameters: {'alpha': 0.5068236198650523, 'beta': 0.01211642624518866}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:40,211] Trial 43 finished with value: 11.994888303957087 and parameters: {'alpha': 0.41253864107060645, 'beta': 0.7279243998117385}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:40,456] Trial 44 finished with value: 11.543733277028645 and parameters: {'alpha': 0.5788306714450194, 'beta': 0.9432671624281513}. Best is trial 22 with value: 11.307313541129759.\n",
      "[I 2025-11-30 13:13:40,695] Trial 45 finished with value: 11.294176001345244 and parameters: {'alpha': 0.4927581188754617, 'beta': 0.8708187320719004}. Best is trial 45 with value: 11.294176001345244.\n",
      "[I 2025-11-30 13:13:40,931] Trial 46 finished with value: 11.663230353794251 and parameters: {'alpha': 0.6147914136936964, 'beta': 0.8667457096418492}. Best is trial 45 with value: 11.294176001345244.\n",
      "[I 2025-11-30 13:13:41,168] Trial 47 finished with value: 11.966563069147101 and parameters: {'alpha': 0.37318355754801197, 'beta': 0.9886791342549974}. Best is trial 45 with value: 11.294176001345244.\n",
      "[I 2025-11-30 13:13:41,411] Trial 48 finished with value: 14.752735208660036 and parameters: {'alpha': 0.8341636583650839, 'beta': 0.9425901421095756}. Best is trial 45 with value: 11.294176001345244.\n",
      "[I 2025-11-30 13:13:41,646] Trial 49 finished with value: 11.514570977453996 and parameters: {'alpha': 0.4605040004853393, 'beta': 0.7432185861298923}. Best is trial 45 with value: 11.294176001345244.\n",
      "  Mejor alpha: 0.4928\n",
      "  Mejor beta: 0.8708\n",
      "  Mejor RMSE: 11.2942\n",
      "  Método usado: Expanding Window\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DE MEJORES PARÁMETROS\n",
      "================================================================================\n",
      "\n",
      "producto1:\n",
      "  Alpha óptimo: 0.5282\n",
      "  Beta óptimo: 0.8109\n",
      "  RMSE: 6.3428\n",
      "  Método de validación: Expanding Window\n",
      "\n",
      "producto2:\n",
      "  Alpha óptimo: 0.4928\n",
      "  Beta óptimo: 0.8708\n",
      "  RMSE: 11.2942\n",
      "  Método de validación: Expanding Window\n"
     ]
    }
   ],
   "source": [
    "# Determinar el mejor método de validación para cada producto\n",
    "mejor_metodo_por_producto = {}\n",
    "\n",
    "for producto in df.columns:\n",
    "    producto_df = df_comparacion[df_comparacion['Producto'] == producto]\n",
    "    mejor_idx = producto_df['RMSE_Promedio'].idxmin()\n",
    "    mejor_metodo = producto_df.loc[mejor_idx, 'Validacion']\n",
    "    mejor_metodo_por_producto[producto] = mejor_metodo\n",
    "    print(f\"{producto}: Mejor método = {mejor_metodo}\")\n",
    "\n",
    "# Realizar optimización bayesiana para cada producto usando su mejor método\n",
    "mejores_params = {}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMIZACIÓN BAYESIANA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for producto in df.columns:\n",
    "    print(f\"\\n--- Optimizando {producto} ---\")\n",
    "    data = df[producto].values\n",
    "    mejor_metodo = mejor_metodo_por_producto[producto]\n",
    "    \n",
    "    # Crear función objetivo según el mejor método\n",
    "    if mejor_metodo == 'Walk-Forward':\n",
    "        objective_func = lambda trial: objective_walk_forward(trial, data, TRAIN_SIZE_MIN)\n",
    "    elif mejor_metodo == 'Rolling Window':\n",
    "        objective_func = lambda trial: objective_rolling_window(trial, data, TRAIN_WINDOW_SIZE)\n",
    "    else:  # Expanding Window\n",
    "        objective_func = lambda trial: objective_expanding_window(trial, data, TRAIN_SIZE_MIN)\n",
    "    \n",
    "    # Crear estudio de Optuna\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
    "    \n",
    "    # Ejecutar optimización\n",
    "    study.optimize(objective_func, n_trials=50, show_progress_bar=True)\n",
    "    \n",
    "    mejores_params[producto] = {\n",
    "        'alpha': study.best_params['alpha'],\n",
    "        'beta': study.best_params['beta'],\n",
    "        'best_rmse': study.best_value,\n",
    "        'metodo_validacion': mejor_metodo\n",
    "    }\n",
    "    \n",
    "    print(f\"  Mejor alpha: {study.best_params['alpha']:.4f}\")\n",
    "    print(f\"  Mejor beta: {study.best_params['beta']:.4f}\")\n",
    "    print(f\"  Mejor RMSE: {study.best_value:.4f}\")\n",
    "    print(f\"  Método usado: {mejor_metodo}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN DE MEJORES PARÁMETROS\")\n",
    "print(\"=\" * 80)\n",
    "for producto, params in mejores_params.items():\n",
    "    print(f\"\\n{producto}:\")\n",
    "    print(f\"  Alpha óptimo: {params['alpha']:.4f}\")\n",
    "    print(f\"  Beta óptimo: {params['beta']:.4f}\")\n",
    "    print(f\"  RMSE: {params['best_rmse']:.4f}\")\n",
    "    print(f\"  Método de validación: {params['metodo_validacion']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43462c1",
   "metadata": {},
   "source": [
    "## Modelo Final para Producción\n",
    "\n",
    "Entrenamos el modelo final con los mejores parámetros encontrados usando todos los datos disponibles y realizamos predicciones para producción (1 pronóstico para el siguiente mes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab1d5b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTRENAMIENTO DE MODELOS FINALES PARA PRODUCCIÓN\n",
      "================================================================================\n",
      "\n",
      "--- producto1 ---\n",
      "  Alpha usado: 0.5282\n",
      "  Beta usado: 0.8109\n",
      "  Último valor observado: 141.9909\n",
      "  Predicción para el próximo mes: 132.3972\n",
      "\n",
      "--- producto2 ---\n",
      "  Alpha usado: 0.4928\n",
      "  Beta usado: 0.8708\n",
      "  Último valor observado: 676.0581\n",
      "  Predicción para el próximo mes: 692.2846\n",
      "\n",
      "================================================================================\n",
      "PREDICCIONES FINALES PARA PRODUCCIÓN\n",
      "================================================================================\n",
      "                producto1   producto2\n",
      "Siguiente_Mes  132.397207  692.284626\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelos finales para cada producto con los mejores parámetros\n",
    "modelos_finales = {}\n",
    "predicciones_finales = {}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENTRENAMIENTO DE MODELOS FINALES PARA PRODUCCIÓN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for producto in df.columns:\n",
    "    print(f\"\\n--- {producto} ---\")\n",
    "    data = df[producto].values\n",
    "    alpha_optimo = mejores_params[producto]['alpha']\n",
    "    beta_optimo = mejores_params[producto]['beta']\n",
    "    \n",
    "    # Entrenar modelo final con todos los datos\n",
    "    data_series = pd.Series(data)\n",
    "    model = ExponentialSmoothing(\n",
    "        data_series,\n",
    "        trend='add',\n",
    "        seasonal=None,\n",
    "        initialization_method='estimated'\n",
    "    )\n",
    "    fit = model.fit(smoothing_level=alpha_optimo, smoothing_trend=beta_optimo, optimized=False)\n",
    "    \n",
    "    modelos_finales[producto] = fit\n",
    "    \n",
    "    # Realizar predicción para el próximo mes (1 solo pronóstico)\n",
    "    forecast_horizon = 1\n",
    "    forecast = fit.forecast(steps=forecast_horizon)\n",
    "    \n",
    "    # Extraer el valor de la predicción (manejar tanto Series como array)\n",
    "    if hasattr(forecast, 'iloc'):\n",
    "        forecast_value = float(forecast.iloc[0])\n",
    "    elif hasattr(forecast, 'values'):\n",
    "        forecast_value = float(forecast.values[0])\n",
    "    else:\n",
    "        forecast_value = float(forecast[0])\n",
    "    \n",
    "    predicciones_finales[producto] = forecast_value\n",
    "    \n",
    "    print(f\"  Alpha usado: {alpha_optimo:.4f}\")\n",
    "    print(f\"  Beta usado: {beta_optimo:.4f}\")\n",
    "    print(f\"  Último valor observado: {data[-1]:.4f}\")\n",
    "    print(f\"  Predicción para el próximo mes: {forecast_value:.4f}\")\n",
    "\n",
    "# Crear DataFrame con las predicciones\n",
    "df_predicciones = pd.DataFrame([predicciones_finales])\n",
    "df_predicciones.index = ['Siguiente_Mes']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREDICCIONES FINALES PARA PRODUCCIÓN\")\n",
    "print(\"=\" * 80)\n",
    "print(df_predicciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8496f3c",
   "metadata": {},
   "source": [
    "## Resumen Final\n",
    "\n",
    "### Resultados de Validación\n",
    "\n",
    "- **Walk-Forward Validation**: Se evaluó el modelo avanzando paso a paso en el tiempo\n",
    "- **Rolling Window Validation**: Se evaluó con una ventana fija que se desplaza\n",
    "- **Expanding Window Validation**: Se evaluó con una ventana que crece progresivamente\n",
    "\n",
    "### Optimización Bayesiana\n",
    "\n",
    "Se utilizó Optimización Bayesiana (Optuna) para encontrar los mejores parámetros alpha y beta para cada producto, usando el método de validación que obtuvo el menor RMSE promedio.\n",
    "\n",
    "### Modelo Final\n",
    "\n",
    "Los modelos finales fueron entrenados con todos los datos disponibles usando los mejores parámetros encontrados (alpha y beta), y están listos para realizar predicciones en producción para el siguiente mes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
